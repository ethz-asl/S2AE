{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampled Dataset of KITTI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from matplotlib import cm\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from sphere import Sphere\n",
    "from dh_grid import DHGrid\n",
    "from laserscan import SemLaserScan\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.protos import segmentation_metrics_pb2\n",
    "from waymo_open_dataset.protos import segmentation_submission_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/media/scratch/berlukas/waymo'\n",
    "FILENAME = f'{dataroot}/individual_files_training_segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_range_image_to_point_cloud_labels(frame,\n",
    "                                              range_images,\n",
    "                                              segmentation_labels,\n",
    "                                              ri_index=0):\n",
    "  \"\"\"Convert segmentation labels from range images to point clouds.\n",
    "\n",
    "  Args:\n",
    "    frame: open dataset frame\n",
    "    range_images: A dict of {laser_name, [range_image_first_return,\n",
    "       range_image_second_return]}.\n",
    "    segmentation_labels: A dict of {laser_name, [range_image_first_return,\n",
    "       range_image_second_return]}.\n",
    "    ri_index: 0 for the first return, 1 for the second return.\n",
    "\n",
    "  Returns:\n",
    "    point_labels: {[N, 2]} list of 3d lidar points's segmentation labels. 0 for\n",
    "      points that are not labeled.\n",
    "  \"\"\"\n",
    "  calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)\n",
    "  point_labels = []\n",
    "  for c in calibrations:\n",
    "    range_image = range_images[c.name][ri_index]\n",
    "    range_image_tensor = tf.reshape(\n",
    "        tf.convert_to_tensor(range_image.data), range_image.shape.dims)\n",
    "    range_image_mask = range_image_tensor[..., 0] > 0\n",
    "\n",
    "    if c.name in segmentation_labels:\n",
    "      sl = segmentation_labels[c.name][ri_index]\n",
    "      sl_tensor = tf.reshape(tf.convert_to_tensor(sl.data), sl.shape.dims)\n",
    "      sl_points_tensor = tf.gather_nd(sl_tensor, tf.where(range_image_mask))\n",
    "    else:\n",
    "      num_valid_point = tf.math.reduce_sum(tf.cast(range_image_mask, tf.int32))\n",
    "      sl_points_tensor = tf.zeros([num_valid_point, 2], dtype=tf.int32)\n",
    "      \n",
    "    point_labels.append(sl_points_tensor.numpy())\n",
    "  return point_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading 30 clouds.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
    "all_sem_clouds = []\n",
    "k = 0\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    \n",
    "    if frame.lasers[0].ri_return1.segmentation_label_compressed:\n",
    "        (range_images, camera_projections, segmentation_labels, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)\n",
    "        points, cp_points = frame_utils.convert_range_image_to_point_cloud(frame, range_images, camera_projections, range_image_top_pose, keep_polar_features=True)\n",
    "        point_labels = convert_range_image_to_point_cloud_labels(frame, range_images, segmentation_labels)\n",
    "        \n",
    "        points_all = np.concatenate(points, axis=0) # 3d points in vehicle frame.\n",
    "        points_all = points_all[:, [3, 4, 5, 1]]\n",
    "        point_labels_all = np.concatenate(point_labels, axis=0) # point labels.\n",
    "        point_labels_all = np.reshape(point_labels_all[:,1], (point_labels_all.shape[0], 1))\n",
    "        \n",
    "        point_xyzil = np.hstack((points_all, point_labels_all))\n",
    "        all_sem_clouds.append(point_xyzil)\n",
    "        \n",
    "print(f'Finished Loading {len(all_sem_clouds)} clouds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{dataroot}/test.npy', point_xyzil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sem_clouds = []\n",
    "\n",
    "def progresser(sample_idx, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "#     sample_sphere = Sphere(sample)\n",
    "    sample_sphere = all_sem_clouds[sample_idx]\n",
    "    features = sample_sphere.sampleUsingGrid(grid)\n",
    "    return features\n",
    "\n",
    "def get_pointcloud_at(scan, name, label):\n",
    "    pointclouds = []            \n",
    "    scan.open_scan(name)\n",
    "    scan.open_label(label)\n",
    "    scan.colorize()\n",
    "\n",
    "    pc = np.column_stack((scan.points, scan.remissions, scan.sem_label))\n",
    "#     mask = pc[:,4] > 0 # Filter based on labeled data.        \n",
    "    pointclouds.append(pc)\n",
    "    return pointclouds\n",
    "\n",
    "def get_map_at(scan, names, labels, indices):\n",
    "    pointclouds = []    \n",
    "    for idx in indices:\n",
    "        scan.open_scan(names[idx])\n",
    "        scan.open_label(labels[idx])\n",
    "        scan.colorize()\n",
    "        \n",
    "        pc = np.column_stack((scan.points, scan.remissions, scan.sem_label))\n",
    "        mask = pc[:,4] > 0 # Filter based on labeled data.        \n",
    "        pointclouds.append(pc[mask])\n",
    "    return pointclouds\n",
    "\n",
    "def retrieve_poses_at(all_poses, indices):\n",
    "    poses = []\n",
    "    for idx in indices:\n",
    "        poses.append(all_poses[idx])\n",
    "    return poses\n",
    "\n",
    "def combine_pointclouds(pointclouds, poses):\n",
    "    n_data = len(poses)\n",
    "    \n",
    "    pivot = n_data // 2  \n",
    "    T_G_L_pivot = poses[pivot]\n",
    "    T_L_pivot_G = np.linalg.inv(T_G_L_pivot)\n",
    "\n",
    "    acc_points = pointclouds[pivot]\n",
    "    for i in range(0, n_data):\n",
    "        if i == pivot:\n",
    "            continue\n",
    "\n",
    "        T_G_L = poses[i]\n",
    "        T_L_pivot_L = T_L_pivot_G @ T_G_L\n",
    "\n",
    "        points = Utils.transform_pointcloud(pointclouds[i], T_L_pivot_L)\n",
    "        acc_points = np.append(acc_points, points, axis=0)                    \n",
    "    \n",
    "    return acc_points\n",
    "\n",
    "CFG = load_config_file(config_file)\n",
    "color_dict = CFG[\"color_map\"]\n",
    "nclasses = len(color_dict)\n",
    "scan = SemLaserScan(nclasses, color_dict, project=False)\n",
    "bw = 100\n",
    "assert CFG is not None\n",
    "  \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "for seq in sequences:\n",
    "    print(f'Loading sequence {seq}.')    \n",
    "    scan_names, label_names = load_sequence(dataroot, seq)\n",
    "    calib = parse_calibration(dataroot, seq)\n",
    "    poses = parse_poses(dataroot, seq, calib)    \n",
    "    n_scans = len(scan_names)    \n",
    "    print(f'This sequence has {len(poses)} data elements.')\n",
    "        \n",
    "    all_sem_clouds = []\n",
    "#     n_scans = 1000\n",
    "    for i in range(0, n_scans):                \n",
    "        pointcloud = get_pointcloud_at(scan, scan_names[i], label_names[i])        \n",
    "        # all_sem_clouds.append(Sphere(pointcloud[0]))\n",
    "        all_sem_clouds.append(pointcloud[0])\n",
    "        \n",
    "    print(f\"Loading complete. Computing features...\")\n",
    "    # parallel\n",
    "    sem_idx = np.arange(0, len(all_sem_clouds))\n",
    "    sample_func = partial(progresser, grid=grid)\n",
    "    sem_features = process_map(sample_func, sem_idx, max_workers=16)            \n",
    "\n",
    "    filename = f\"{export_ds}/clouds-{seq}.npy\"\n",
    "    np.save(filename, sem_features)\n",
    "    print(f\"Wrote features to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def visualizeRawPointcloud(pcl, val):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcl[:, 0:3])\n",
    "    colors = mapIntensityToRGB(val)\n",
    "#     colors = scan.sem_color_lut[pcl[:,4].astype(np.int)]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.visualization.draw_geometries([pcd])    \n",
    "    \n",
    "def createGrid_old(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([n_grid * n_grid, 2])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])\n",
    "    return cart_grid\n",
    "\n",
    "def create_sampling_sphere(bw):\n",
    "    grid = createGrid_old(bw)\n",
    "    xyz_grid = convertGridToEuclidean_old(grid)\n",
    "    intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "    sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "    return sampling_grid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = all_sem_clouds[0].point_cloud\n",
    "visualizeRawPointcloud(pc, pc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_features[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{export_ds}/clouds-08-2.npy\"\n",
    "sem_features = np.load(filename)\n",
    "\n",
    "\n",
    "cur_sem_cloud = sem_features[0, :, :, :]\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "print(f'{cur_sem_cloud.shape}')\n",
    "pc = create_sampling_sphere(bw)\n",
    "points_xyz = pc.T[:,0:3]\n",
    "print(f\"sampling pointcloud shape is {points_xyz.shape}\")\n",
    "print(f\"feature shape is {cur_sem_cloud.shape}\")\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "# points_xyzn = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "\n",
    "visualizeRawPointcloud(points_xyzl, points_xyzl[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
