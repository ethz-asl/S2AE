{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the GT for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "from sphere import Sphere\n",
    "from visualize import Visualize\n",
    "from semantic_classes import SemanticClasses\n",
    "    \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/nuscenes/clouds1_val_bw50.npy\n",
      "Shape of sem clouds is (500, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# NUSCENES LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# export_ds = '/media/berlukas/Data2/datasets/nuscenes/processed/'\n",
    "export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "sem_clouds_filename = f\"{export_ds}/clouds1_val_bw50.npy\"\n",
    "\n",
    "print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/berlukas/SSD_1TB/s2ae/kitti/val//clouds-08-rotated-val-180.npy\n",
      "Shape of sem clouds is (500, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# KITTI LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# export_ds = '/media/scratch/berlukas/kitti/features50'\n",
    "# export_ds = '/media/berlukas/Data/data/datasets/s2ae/cluster/val_kitti/'\n",
    "export_ds = '/media/berlukas/SSD_1TB/s2ae/kitti/val/'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_50/features02.npy\n",
      "Shape of sem clouds is (500, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# WAYMO LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/waymo/extracted/features_50'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/poss/features50/clouds-05.npy\n",
      "Shape of sem clouds before intensity removal is (500, 3, 100, 100)\n",
      "Shape of sem clouds is (500, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# POSS LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/poss/features50'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))    \n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before intensity removal is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/usl/features50/clouds-03.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/usl/features50/clouds-12.npy\n",
      "Shape of sem clouds before is (600, 3, 100, 100)\n",
      "Shape of sem clouds is (600, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# USL LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/usl/features50'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/berlukas/Data/data/datasets/s2ae/pc urban/processed/features50/clouds.npy\n",
      "Shape of sem clouds before is (573, 3, 100, 100)\n",
      "Shape of sem clouds is (573, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# A2D2 LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/berlukas/Data/data/datasets/s2ae/pc urban/processed/features50'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2D2 LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/a2d2/features50'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94501bd1bf0e4040abef6211a237b2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/573 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of classes is (573, 10000)\n",
      "we have 21 classes in the dataset. That is:\n",
      "[-1.  0.  1.  2.  3.  4.  6.  7.  8.  9. 10. 11. 13. 14. 15. 17. 18. 26.\n",
      " 28. 29. 30.]\n"
     ]
    }
   ],
   "source": [
    "n_clouds = sem_cloud_features.shape[0]\n",
    "idx_sem = 1\n",
    "classes = [None] * n_clouds\n",
    "for i in tqdm(range(0, n_clouds)):\n",
    "    sem_cloud = np.reshape(sem_cloud_features[i,:,:,:], (2, -1)).T    \n",
    "    classes[i] = sem_cloud[:, idx_sem]\n",
    "classes = np.array(classes[:])\n",
    "print(f\"shape of classes is {classes.shape}\")\n",
    "unique_classes = np.unique(classes)\n",
    "n_unique_classes = len(unique_classes)\n",
    "print(f\"we have {n_unique_classes} classes in the dataset. That is:\")\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the features and generate the GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating for 573 features and data of size: (100/100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadf693b7c8842deb488cdf4e769988f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/573 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = sem_cloud_features.shape[0]\n",
    "n_rows = sem_cloud_features.shape[2]\n",
    "n_cols = sem_cloud_features.shape[3]\n",
    "idx_range = 0\n",
    "idx_sem = 1\n",
    "max_range = 20\n",
    "\n",
    "print(f'Iterating for {n_features} features and data of size: ({n_rows}/{n_cols})')\n",
    "for feature in tqdm(range(n_features)):\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):            \n",
    "            cur_class = int(sem_cloud_features[feature, idx_sem, i, j])\n",
    "#             mapped_class = SemanticClasses.map_nuscenes_label_old(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_waymo_to_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_kitti_to_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_poss_to_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_usl_to_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_a2d2_to_nuscenes_label(cur_class)\n",
    "            mapped_class = SemanticClasses.map_pc_urban_to_nuscenes_label(cur_class)\n",
    "            if (sem_cloud_features[feature, idx_range, i, j] <= max_range):\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = mapped_class\n",
    "            else:\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote features to /media/berlukas/Data/data/datasets/s2ae/pc urban/processed/features50/sem_clouds_pc_urban_bw50.npy\n"
     ]
    }
   ],
   "source": [
    "filename = 'sem_clouds_pc_urban_bw50'\n",
    "sem_clouds_gt_filename = f'{export_ds}/{filename}.npy'\n",
    "np.save(sem_clouds_gt_filename, sem_cloud_features)\n",
    "print(f\"Wrote features to {sem_clouds_gt_filename}\")\n",
    "\n",
    "# Create a tiny dataset\n",
    "# n_process = 400\n",
    "# sem_clouds_gt_tiny_filename = f'{export_ds}/{filename}_tiny.npy'\n",
    "# np.save(sem_clouds_gt_tiny_filename, sem_cloud_features[0:n_process, :, :, :])\n",
    "# print(f\"Wrote tiny features to {sem_clouds_gt_tiny_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have in total 5000\n",
      "we will keep 4500 for training and 500 for validation.\n",
      "init shape is (5000, 2, 100, 100)\n",
      "training shape is (4500, 2, 100, 100), validation shape is (500, 2, 100, 100)\n",
      "Wrote features to /media/scratch/berlukas/nuscenes/sem_clouds3.npy\n",
      "Wrote tiny features to /media/scratch/berlukas/nuscenes/sem_clouds_val_200.npy\n"
     ]
    }
   ],
   "source": [
    "# Remove a few samples for validation\n",
    "n_clouds = sem_cloud_features.shape[0]\n",
    "print(f'we have in total {n_clouds}')\n",
    "n_train = n_clouds - 500\n",
    "n_val = n_clouds - n_train\n",
    "print(f'we will keep {n_train} for training and {n_val} for validation.')\n",
    "\n",
    "print(f'init shape is {sem_cloud_features.shape}')\n",
    "sem_train = sem_cloud_features[:n_train, :, :, :]\n",
    "sem_val = sem_cloud_features[n_train:, :, :, :]\n",
    "print(f'training shape is {sem_train.shape}, validation shape is {sem_val.shape}')\n",
    "\n",
    "np.save(f'{export_ds}/sem_clouds3.npy', sem_train)\n",
    "np.save(f'{export_ds}/sem_clouds_val_200.npy', sem_val)\n",
    "\n",
    "print(f'Wrote features to {export_ds}/sem_clouds3.npy')\n",
    "print(f'Wrote tiny features to {export_ds}/sem_clouds_val_200.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_val_tiny = sem_val[:500, :, :, :]\n",
    "np.save(f'{export_ds}/sem_clouds_val_tiny.npy', sem_val_tiny)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
