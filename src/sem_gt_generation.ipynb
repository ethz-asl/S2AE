{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the GT for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "from sphere import Sphere\n",
    "from visualize import Visualize\n",
    "from semantic_classes import SemanticClasses\n",
    "    \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/nuscenes/clouds1_bw120_range_sem.npy\n",
      "Shape of sem clouds is (11230, 2, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "# NUSCENES LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# export_ds = '/media/berlukas/Data2/datasets/nuscenes/processed/'\n",
    "export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "sem_clouds_filename = f\"{export_ds}/clouds1_bw120_range_sem.npy\"\n",
    "\n",
    "print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/kitti/processed/clouds-08.npy\n",
      "Shape of sem clouds is (4071, 2, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "# KITTI LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/kitti/processed'\n",
    "sem_clouds_filename = f\"{export_ds}/clouds-08.npy\"\n",
    "\n",
    "print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features06.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features01.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features05.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features11.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features09.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features10.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features08.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features02.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features00.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features04.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features07.npy\n",
      "Loading from sem clouds from /media/scratch/berlukas/waymo/extracted/features_120/features03.npy\n",
      "Shape of sem clouds is (8879, 2, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "# WAYMO LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/waymo/extracted/features_120'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from sem clouds from /media/scratch/berlukas/poss/features120/clouds-01.npy\n",
      "Shape of sem clouds before intensity removal is (500, 3, 240, 240)\n",
      "Shape of sem clouds is (500, 2, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "# POSS LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '/media/scratch/berlukas/poss/features120'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))    \n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before intensity removal is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only processing val\n",
    "# n_clouds = sem_cloud_features.shape[0]\n",
    "# print(f'we have in total {n_clouds}')\n",
    "# n_train = n_clouds - 6053\n",
    "# n_val = n_clouds - n_train\n",
    "# print(f'we will keep {n_train} for training and {n_val} for validation.')\n",
    "# sem_cloud_features = sem_cloud_features[n_train:, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1931cfc5f3614e3c9b65c546c91d7187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of classes is (500, 57600)\n",
      "we have 20 classes in the dataset. That is:\n",
      "[-1.  0.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19.\n",
      " 21. 22.]\n"
     ]
    }
   ],
   "source": [
    "n_clouds = sem_cloud_features.shape[0]\n",
    "idx_sem = 1\n",
    "classes = [None] * n_clouds\n",
    "for i in tqdm(range(0, n_clouds)):\n",
    "    sem_cloud = np.reshape(sem_cloud_features[i,:,:,:], (2, -1)).T    \n",
    "    classes[i] = sem_cloud[:, idx_sem]\n",
    "classes = np.array(classes[:])\n",
    "print(f\"shape of classes is {classes.shape}\")\n",
    "unique_classes = np.unique(classes)\n",
    "n_unique_classes = len(unique_classes)\n",
    "print(f\"we have {n_unique_classes} classes in the dataset. That is:\")\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clouds = sem_cloud_features.shape[0]\n",
    "idx_sem = 2\n",
    "classes = [None] * n_clouds\n",
    "for i in tqdm(range(0, n_clouds)):\n",
    "    sem_cloud = np.reshape(sem_cloud_features[i,:,:,:], (3, -1)).T    \n",
    "    classes[i] = sem_cloud[:,idx_sem]\n",
    "classes = np.array(classes[:])\n",
    "print(f\"shape of classes is {classes.shape}\")\n",
    "unique_classes = np.unique(classes)\n",
    "n_unique_classes = len(unique_classes)\n",
    "print(f\"we have {n_unique_classes} classes in the dataset.\")\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the features and generate the GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating for 500 features and data of size: (240/240)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a98a1fee40a4965990da0d160631dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_features = sem_cloud_features.shape[0]\n",
    "n_rows = sem_cloud_features.shape[2]\n",
    "n_cols = sem_cloud_features.shape[3]\n",
    "idx_range = 0\n",
    "idx_sem = 1\n",
    "max_range = 35\n",
    "\n",
    "print(f'Iterating for {n_features} features and data of size: ({n_rows}/{n_cols})')\n",
    "for feature in tqdm(range(n_features)):\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):            \n",
    "            cur_class = int(sem_cloud_features[feature, idx_sem, i, j])\n",
    "            # mapped_class = SemanticClasses.map_nuscenes_label_old(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_waymo_to_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_kitti_to_nuscenes_label(cur_class)\n",
    "            mapped_class = SemanticClasses.map_poss_to_nuscenes_label(cur_class)\n",
    "            if (sem_cloud_features[feature, idx_range, i, j] <= max_range):\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = mapped_class\n",
    "            else:\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3159880c51408497c25a11b5873a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sem_cloud_features = sem_cloud_features[0:10,:,:,:]\n",
    "idx_sem = 2\n",
    "n_data = sem_cloud_features.shape[0]\n",
    "n_features = sem_cloud_features.shape[1]\n",
    "n_rows = sem_cloud_features.shape[2]\n",
    "n_cols = sem_cloud_features.shape[3]\n",
    "\n",
    "idx_intensity = 1;\n",
    "for feature in tqdm(range(n_data)):\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            cur_class = int(sem_cloud_features[feature, idx_sem, i, j])            \n",
    "            mapped_class = SemanticClasses.map_kitti_to_nuscenes_label(cur_class)\n",
    "            \n",
    "            cur_intensity = sem_cloud_features[feature, idx_intensity, i, j]\n",
    "#             if cur_intensity > 0:\n",
    "#                 cur_intensity = ((cur_intensity ) / 0.16)\n",
    "#                 cur_intensity = cur_intensity * 255 \n",
    "            \n",
    "#             mapped_class = map_nuscenes_label(cur_class)\n",
    "#             mapped_class = map_nuscenes_label_old(cur_class)\n",
    "            sem_cloud_features[feature, idx_sem, i, j] = mapped_class\n",
    "#             sem_cloud_features[feature, idx_intensity, i, j] = int(cur_intensity)\n",
    "#             if cur_intensity > 1:\n",
    "#                 print(sem_cloud_features[feature, idx_intensity, i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote features to /media/scratch/berlukas/poss/features120/sem_clouds_poss_01_bw120.npy\n"
     ]
    }
   ],
   "source": [
    "filename = 'sem_clouds_poss_01_bw120'\n",
    "sem_clouds_gt_filename = f'{export_ds}/{filename}.npy'\n",
    "np.save(sem_clouds_gt_filename, sem_cloud_features)\n",
    "print(f\"Wrote features to {sem_clouds_gt_filename}\")\n",
    "\n",
    "# Create a tiny dataset\n",
    "# n_process = 400\n",
    "# sem_clouds_gt_tiny_filename = f'{export_ds}/{filename}_tiny.npy'\n",
    "# np.save(sem_clouds_gt_tiny_filename, sem_cloud_features[0:n_process, :, :, :])\n",
    "# print(f\"Wrote tiny features to {sem_clouds_gt_tiny_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have in total 988\n",
      "we will keep 488 for training and 500 for validation.\n",
      "init shape is (988, 2, 240, 240)\n",
      "training shape is (488, 2, 240, 240), validation shape is (500, 2, 240, 240)\n",
      "Wrote features to /media/scratch/berlukas/poss/features120/sem_clouds3.npy\n",
      "Wrote tiny features to /media/scratch/berlukas/poss/features120/sem_clouds_val_200.npy\n"
     ]
    }
   ],
   "source": [
    "# Remove a few samples for validation\n",
    "n_clouds = sem_cloud_features.shape[0]\n",
    "print(f'we have in total {n_clouds}')\n",
    "n_train = n_clouds - 500\n",
    "n_val = n_clouds - n_train\n",
    "print(f'we will keep {n_train} for training and {n_val} for validation.')\n",
    "\n",
    "print(f'init shape is {sem_cloud_features.shape}')\n",
    "sem_train = sem_cloud_features[:n_train, :, :, :]\n",
    "sem_val = sem_cloud_features[n_train:, :, :, :]\n",
    "print(f'training shape is {sem_train.shape}, validation shape is {sem_val.shape}')\n",
    "\n",
    "np.save(f'{export_ds}/sem_clouds3.npy', sem_train)\n",
    "np.save(f'{export_ds}/sem_clouds_val_200.npy', sem_val)\n",
    "\n",
    "print(f'Wrote features to {export_ds}/sem_clouds3.npy')\n",
    "print(f'Wrote tiny features to {export_ds}/sem_clouds_val_200.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_val_tiny = sem_val[:500, :, :, :]\n",
    "np.save(f'{export_ds}/sem_clouds_val_tiny.npy', sem_val_tiny)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
