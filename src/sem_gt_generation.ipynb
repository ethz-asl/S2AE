{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the GT for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "\n",
    "from sphere import Sphere\n",
    "from visualize import Visualize\n",
    "from semantic_classes import SemanticClasses\n",
    "    \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUSCENES LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "sem_clouds_filename = f\"{export_ds}/teaser.npy\"\n",
    "\n",
    "print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "# sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KITTI LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAYMO LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSS LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))    \n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before intensity removal is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USL LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC Urban LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2D2 LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM LOADER\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "export_ds = '...'\n",
    "archives = os.listdir(export_ds)\n",
    "sem_cloud_features = None\n",
    "for archive in archives:\n",
    "    sem_clouds_filename = f\"{export_ds}/{archive}\"\n",
    "    \n",
    "    print(f\"Loading from sem clouds from {sem_clouds_filename}\")\n",
    "    if sem_cloud_features is None:\n",
    "        sem_cloud_features = np.load(sem_clouds_filename)\n",
    "    else:\n",
    "        features = np.load(sem_clouds_filename)\n",
    "        sem_cloud_features = np.concatenate((sem_cloud_features, features))\n",
    "    \n",
    "# Remove intensity channel\n",
    "print(f\"Shape of sem clouds before is {sem_cloud_features.shape}\")\n",
    "sem_cloud_features = sem_cloud_features[:, [0, 2], :, :]\n",
    "print(f\"Shape of sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clouds = sem_cloud_features.shape[0]\n",
    "idx_sem = 1\n",
    "classes = [None] * n_clouds\n",
    "for i in tqdm(range(0, n_clouds)):\n",
    "    sem_cloud = np.reshape(sem_cloud_features[i,:,:,:], (2, -1)).T    \n",
    "    classes[i] = sem_cloud[:, idx_sem]\n",
    "classes = np.array(classes[:])\n",
    "print(f\"shape of classes is {classes.shape}\")\n",
    "unique_classes = np.unique(classes)\n",
    "n_unique_classes = len(unique_classes)\n",
    "print(f\"we have {n_unique_classes} classes in the dataset. That is:\")\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the features and generate the GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = sem_cloud_features.shape[0]\n",
    "n_rows = sem_cloud_features.shape[2]\n",
    "n_cols = sem_cloud_features.shape[3]\n",
    "idx_range = 0\n",
    "idx_sem = 1\n",
    "max_range = 50\n",
    "\n",
    "print(f'Iterating for {n_features} features and data of size: ({n_rows}/{n_cols})')\n",
    "for feature in tqdm(range(n_features)):\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):            \n",
    "            cur_class = int(sem_cloud_features[feature, idx_sem, i, j])\n",
    "#             mapped_class = SemanticClasses.map_nuscenes_label_old(cur_class)\n",
    "            mapped_class = SemanticClasses.map_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_waymo_to_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_kitti_to_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_poss_to_nuscenes_label(cur_class)\n",
    "#             mapped_class = SemanticClasses.map_usl_to_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_a2d2_to_nuscenes_label(cur_class)\n",
    "            # mapped_class = SemanticClasses.map_pc_urban_to_nuscenes_label(cur_class)\n",
    "            if (sem_cloud_features[feature, idx_range, i, j] <= max_range):\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = mapped_class\n",
    "            else:\n",
    "                sem_cloud_features[feature, idx_sem, i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sem_teaser'\n",
    "sem_clouds_gt_filename = f'{export_ds}/{filename}.npy'\n",
    "np.save(sem_clouds_gt_filename, sem_cloud_features)\n",
    "print(f\"Wrote features to {sem_clouds_gt_filename}\")\n",
    "\n",
    "# Create a tiny dataset\n",
    "# n_process = 400\n",
    "# sem_clouds_gt_tiny_filename = f'{export_ds}/{filename}_tiny.npy'\n",
    "# np.save(sem_clouds_gt_tiny_filename, sem_cloud_features[0:n_process, :, :, :])\n",
    "# print(f\"Wrote tiny features to {sem_clouds_gt_tiny_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a few samples for validation\n",
    "n_clouds = sem_cloud_features.shape[0]\n",
    "print(f'we have in total {n_clouds}')\n",
    "n_train = n_clouds - 500\n",
    "n_val = n_clouds - n_train\n",
    "print(f'we will keep {n_train} for training and {n_val} for validation.')\n",
    "\n",
    "print(f'init shape is {sem_cloud_features.shape}')\n",
    "sem_train = sem_cloud_features[:n_train, :, :, :]\n",
    "sem_val = sem_cloud_features[n_train:, :, :, :]\n",
    "print(f'training shape is {sem_train.shape}, validation shape is {sem_val.shape}')\n",
    "\n",
    "np.save(f'{export_ds}/sem_clouds3.npy', sem_train)\n",
    "np.save(f'{export_ds}/sem_clouds_val_200.npy', sem_val)\n",
    "\n",
    "print(f'Wrote features to {export_ds}/sem_clouds3.npy')\n",
    "print(f'Wrote tiny features to {export_ds}/sem_clouds_val_200.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_val_tiny = sem_val[:500, :, :, :]\n",
    "np.save(f'{export_ds}/sem_clouds_val_tiny.npy', sem_val_tiny)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
