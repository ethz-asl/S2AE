{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPH Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "from nuscenes.utils.data_classes import PointCloud, LidarPointCloud, RadarPointCloud, Box\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from matplotlib import cm\n",
    "from sphere import Sphere\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from functools import partial\n",
    "from dh_grid import DHGrid\n",
    "from sphere import Sphere\n",
    "from img_sphere import ImageSphere, ColorImageSphere\n",
    "from average_meter import AverageMeter\n",
    "import random\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 90.723 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "# dataset_path = '/media/scratch/berlukas/nuscenes'\n",
    "# dataset_path = '/mnt/data/datasets/nuscenes/v1.0-mini/'\n",
    "dataset_path = '/media/berlukas/T7 Touch/data/nuscenes'\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=dataset_path, verbose=True)\n",
    "# nusc = NuScenes(version='v1.0-mini', dataroot=dataset_path, verbose=True)\n",
    "all_cam_strings = ['CAM_FRONT','CAM_FRONT_RIGHT','CAM_BACK_RIGHT','CAM_BACK','CAM_BACK_LEFT','CAM_FRONT_LEFT']\n",
    "lidar_string = 'LIDAR_TOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateGrid(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([2, n_grid, n_grid])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[0, i, j] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[1, i, j] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "\n",
    "def createGrid_old(bw):\n",
    "        n_grid = 2 * bw\n",
    "        k = 0;\n",
    "        points = np.empty([n_grid * n_grid, 2])\n",
    "        for i in range(n_grid):\n",
    "            for j in range(n_grid):\n",
    "                points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "                points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "                k = k + 1;\n",
    "        return points\n",
    "\n",
    "def ConvertGridToEuclidean(grid):\n",
    "    cart_grid = np.zeros([3, grid.shape[1], grid.shape[2]])\n",
    "    cart_grid[0,:,:] = np.multiply(np.sin(grid[0, :,:]), np.cos(grid[1,:,:]))\n",
    "    cart_grid[1,:,:] = np.multiply(np.sin(grid[0, :, :]), np.sin(grid[1, :, :]))\n",
    "    cart_grid[2,:,:] = np.cos(grid[0, :, :])    \n",
    "    return cart_grid\n",
    "\n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])    \n",
    "    return cart_grid\n",
    "\n",
    "def rgb_to_greyscale(r,g,b):\n",
    "    return 0.2126*r + 0.7152*g + 0.0722*b\n",
    "#     return 0.3*r + 0.59*g + 0.11*b    \n",
    "\n",
    "def transform_from_pcl_to_cam(nusc, pointsensor, cam, pc):\n",
    "    # Points live in the point sensor frame. So they need to be transformed via global to the image plane.\n",
    "    # First step: transform the pointcloud to the ego vehicle frame for the timestamp of the sweep.\n",
    "    cs_record = nusc.get('calibrated_sensor', pointsensor['calibrated_sensor_token'])\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(cs_record['translation']))\n",
    "\n",
    "    # Second step: transform from ego to the global frame.\n",
    "    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(poserecord['translation']))\n",
    "\n",
    "    # Third step: transform from global into the ego vehicle frame for the timestamp of the image.\n",
    "    poserecord = nusc.get('ego_pose', cam['ego_pose_token'])\n",
    "    pc.translate(-np.array(poserecord['translation']))\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix.T)\n",
    "\n",
    "    # Fourth step: transform from ego into the camera.\n",
    "    cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "    pc.translate(-np.array(cs_record['translation']))\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix.T)\n",
    "    \n",
    "    return pc\n",
    "\n",
    "def transform_from_cam_to_pcl(nusc, pointsensor, cam, pc):\n",
    "    # Transform from the camera into the vehicle's ego frame\n",
    "    cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])    \n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(cs_record['translation']))\n",
    "    \n",
    "    # Transform from the ego frame (cam) to the global frame\n",
    "    poserecord = nusc.get('ego_pose', cam['ego_pose_token'])\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(poserecord['translation']))\n",
    "        \n",
    "    # Transform from the global frame to the ego frame of the LiDAR.\n",
    "    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])    \n",
    "    pc.translate(-np.array(poserecord['translation']))\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix.T)\n",
    "        \n",
    "    # Transform from the ego frame (LiDAR) to the LiDAR frame\n",
    "    cs_record = nusc.get('calibrated_sensor', pointsensor['calibrated_sensor_token'])    \n",
    "    pc.translate(-np.array(cs_record['translation']))\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix.T)\n",
    "    \n",
    "    return pc\n",
    "\n",
    "def project_pc_on_cam(pc, cam_intrinsics, depths, im):\n",
    "    # Take the actual picture (matrix multiplication with camera-matrix + renormalization).\n",
    "    points = view_points(pc.points[:3, :], cam_intrinsics, normalize=True)\n",
    "\n",
    "    # Remove points that are either outside or behind the camera. Leave a margin of 1 pixel for aesthetic reasons.\n",
    "    # Also make sure points are at least 1m in front of the camera to avoid seeing the lidar points on the camera\n",
    "    # casing for non-keyframes which are slightly out of sync.\n",
    "    min_dist = 0.0001\n",
    "    mask = np.ones(depths.shape[0], dtype=bool)\n",
    "    mask = np.logical_and(mask, depths < -1.0)\n",
    "    mask = np.logical_and(mask, points[0, :] > 1)\n",
    "    mask = np.logical_and(mask, points[0, :] < im.size[0] - 1)\n",
    "    mask = np.logical_and(mask, points[1, :] > 1)\n",
    "    mask = np.logical_and(mask, points[1, :] < im.size[1] - 1)\n",
    "    return points, mask\n",
    "\n",
    "def sample_mono_from_image(im, pc, mask, points):\n",
    "    n_mask = len(mask)\n",
    "        \n",
    "    for i in range(0,n_mask):    \n",
    "        visible = mask[i]\n",
    "        if not visible:\n",
    "            continue\n",
    "        cur_point = (points[0,i], points[1,i])    \n",
    "        px = im.getpixel(cur_point)    \n",
    "        intensity = rgb_to_greyscale(px[0], px[1], px[2])\n",
    "        pc.points[3,i] = intensity\n",
    "    return pc\n",
    "\n",
    "def sample_color_from_image(im, pc, mask, points):\n",
    "    n_mask = len(mask)    \n",
    "    \n",
    "    for i in range(0,n_mask):    \n",
    "        visible = mask[i]\n",
    "        if not visible:\n",
    "            continue\n",
    "        cur_point = (points[0,i], points[1,i])            \n",
    "        pc.points[3:6,i] = im.getpixel(cur_point)\n",
    "    return pc\n",
    "\n",
    "def prepare_for_viz(cloud):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    if cloud.shape[1] == 6:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cloud[:,3:6] / 255.0)\n",
    "    return pcd\n",
    "\n",
    "def visualize_pointcloud(cloud, jupyter = False):\n",
    "    pcd = prepare_for_viz(cloud)\n",
    "    \n",
    "    if jupyter:\n",
    "        self.__visualizeJupyter(pcd)\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "        \n",
    "def mapIntensityToRGB(i):\n",
    "    mask = np.where(i < 0)    \n",
    "    colors = cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "    colors[mask] = 0\n",
    "    return colors\n",
    "\n",
    "def write_pointcloud(cloud, filename):\n",
    "    pcd = prepare_for_viz(cloud)\n",
    "    o3d.io.write_point_cloud(filename, pcd)\n",
    "    \n",
    "def construct_transformation_matrix(R, t):\n",
    "    T = np.eye(4)\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3] = t\n",
    "    return T\n",
    "  \n",
    "class SamplingPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        return 4\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'SamplingPointCloud':\n",
    "        return None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_bw(cls, bw, scale = 100) -> 'SamplingPointCloud':\n",
    "        grid = createGrid_old(bw)\n",
    "        xyz_grid = convertGridToEuclidean_old(grid) * scale\n",
    "        intensities = np.zeros((xyz_grid.shape[0],1), dtype=xyz_grid.dtype)\n",
    "        sampling_grid = np.hstack((xyz_grid, intensities))\n",
    "        return cls(sampling_grid.T)\n",
    "    \n",
    "class ColorSamplingPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        return 6\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'ColorSamplingPointCloud':\n",
    "        return None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_bw(cls, bw, scale = 100) -> 'ColorSamplingPointCloud':\n",
    "        grid = createGrid_old(bw)\n",
    "        xyz_grid = convertGridToEuclidean_old(grid) * scale\n",
    "        rgb = np.zeros((xyz_grid.shape[0], 3), dtype=xyz_grid.dtype)\n",
    "        sampling_grid = np.hstack((xyz_grid, rgb))\n",
    "        return cls(sampling_grid.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# Convert dataset to PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_ds = '/media/berlukas/Data2/datasets/nuscenes/processed/'\n",
    "# export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "# export_images = export_ds + '/SPH_IMAGES/'\n",
    "# export_clouds = export_ds + '/SPH_CLOUDS/'\n",
    "poses_out = export_ds + '/poses.npy'\n",
    "\n",
    "bw = 120\n",
    "scale = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_scenes = 850\n",
      "chunk 1 [0, 283]\n",
      "chunk 2 [283, 566]\n",
      "chunk 3 [566, 850]\n"
     ]
    }
   ],
   "source": [
    "n_scenes = len(nusc.scene)\n",
    "per_chunk = int(n_scenes / 3)\n",
    "\n",
    "chunk1_start = 0\n",
    "chunk1_end = per_chunk\n",
    "# chunk1_end = 10\n",
    "chunk2_start = chunk1_end\n",
    "chunk2_end = chunk2_start + per_chunk\n",
    "chunk3_start = chunk2_end\n",
    "chunk3_end = n_scenes\n",
    "\n",
    "print(f\"n_scenes = {n_scenes}\")\n",
    "print(f\"chunk 1 [{chunk1_start}, {chunk1_end}]\")\n",
    "print(f\"chunk 2 [{chunk2_start}, {chunk2_end}]\")\n",
    "print(f\"chunk 3 [{chunk3_start}, {chunk3_end}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the global LiDAR poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_lidar_pose_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    \n",
    "    cs_record = nusc.get('calibrated_sensor', pointsensor['calibrated_sensor_token'])\n",
    "    R = Quaternion(cs_record['rotation']).rotation_matrix\n",
    "    t = np.array(cs_record['translation'])\n",
    "    T_E_L = construct_transformation_matrix(R, t)\n",
    "\n",
    "    # Second step: transform from ego to the global frame.\n",
    "    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])\n",
    "    R = Quaternion(poserecord['rotation']).rotation_matrix\n",
    "    t = np.array(poserecord['translation'])\n",
    "    T_G_E = construct_transformation_matrix(R, t)\n",
    "         \n",
    "    # T_G_L\n",
    "    return np.matmul(T_G_E, T_E_L), sample['next']\n",
    "\n",
    "def visualize_poses(Ts):\n",
    "    n_poses = len(Ts)\n",
    "    xy = np.empty((2, n_poses))\n",
    "    for i in range(0, n_poses):\n",
    "        xy[0:2, i] = Ts[i][0:2, 3]\n",
    "    \n",
    "    plt.scatter(xy[0,:], xy[1,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenes from 0 to 120.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1206a65471af47b7967ebb31234e72ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading complete. Found 4766 poses.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poses extraction complete.\n"
     ]
    }
   ],
   "source": [
    "start = chunk1_start\n",
    "end = chunk1_end\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "all_poses = []\n",
    "all_scene_poses = [None] * n_scenes\n",
    "for i in tqdm(range(start, end)):\n",
    "    scene_poses = []\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    pose_first, next_sample_token = get_global_lidar_pose_from_token(first_sample_token)\n",
    "    all_poses.append(pose_first)\n",
    "    scene_poses.append(pose_first)\n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "        pose_next, next_sample_token = get_global_lidar_pose_from_token(next_sample_token)    \n",
    "        all_poses.append(pose_next)\n",
    "        scene_poses.append(pose_next)\n",
    "    all_scene_poses[i] = scene_poses    \n",
    "    \n",
    "print(f\"Loading complete. Found {len(all_poses)} poses.\")    \n",
    "visualize_poses(all_poses)\n",
    "np.save(poses_out, all_poses)\n",
    "print(f\"Poses extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the images to spherical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progresser_images(sample, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "    sample_sphere = ImageSphere(sample)\n",
    "    return sample_sphere.sampleUsingGrid(grid)\n",
    "\n",
    "def progresser_color_images(sample, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "    sample_sphere = ColorImageSphere(sample)\n",
    "    return sample_sphere.sampleUsingGrid(grid)\n",
    "\n",
    "def get_sampled_image_sphere_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    pc = SamplingPointCloud.from_bw(bw, scale)\n",
    "\n",
    "    for cam_str in all_cam_strings:          \n",
    "        cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "        im = Image.open(osp.join(dataset_path, cam['filename']))        \n",
    "\n",
    "        # Transform pointcloud into the camera frame\n",
    "        pc = transform_from_pcl_to_cam(nusc, pointsensor, cam, pc)\n",
    "        # Grab the depths (camera frame z axis points away from the camera).\n",
    "        depths = pc.points[2, :]\n",
    "\n",
    "        # Project the points onto the image plane\n",
    "        cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "        intrinsics = np.array(cs_record['camera_intrinsic'])\n",
    "        points, mask = project_pc_on_cam(pc, intrinsics, depths, im)\n",
    "        filtered_points = points[:, mask]\n",
    "        \n",
    "        # Sample the intensity values from the image\n",
    "        # and transform back into the LiDAR frame.\n",
    "        pc = sample_mono_from_image(im, pc, mask, points) \n",
    "        pc = transform_from_cam_to_pcl(nusc, pointsensor, cam, pc) \n",
    "    \n",
    "    # Scale back to the original value but only use xyz.\n",
    "    cloud = pc.points.T\n",
    "    cloud[:,0:3] = cloud[:,0:3] / scale\n",
    "    \n",
    "    return cloud / scale, sample['next']\n",
    "\n",
    "def crop_image(im):\n",
    "    width, height = im.size   # Get dimensions\n",
    "\n",
    "    new_height = 562\n",
    "    new_width = 1000\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    return im.crop((left, top, right, bottom))\n",
    "\n",
    "def get_sampled_color_image_sphere_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    pc = ColorSamplingPointCloud.from_bw(bw, scale)\n",
    "\n",
    "    for cam_str in all_cam_strings:                  \n",
    "        cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "        im = Image.open(osp.join(dataset_path, cam['filename']))\n",
    "#         im.show()\n",
    "                \n",
    "        # Transform pointcloud into the camera frame\n",
    "        pc = transform_from_pcl_to_cam(nusc, pointsensor, cam, pc)\n",
    "        # Grab the depths (camera frame z axis points away from the camera).\n",
    "        depths = pc.points[2, :]\n",
    "\n",
    "        # Project the points onto the image plane\n",
    "        cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "        intrinsics = np.array(cs_record['camera_intrinsic'])\n",
    "        points, mask = project_pc_on_cam(pc, intrinsics, depths, im)\n",
    "        filtered_points = points[:, mask]\n",
    "        \n",
    "        # Sample the intensity values from the image\n",
    "        # and transform back into the LiDAR frame.\n",
    "        pc = sample_color_from_image(im, pc, mask, points) \n",
    "        pc = transform_from_cam_to_pcl(nusc, pointsensor, cam, pc) \n",
    "    \n",
    "    # Scale back to the original value but only use xyz.\n",
    "    cloud = pc.points.T\n",
    "    cloud[:,0:3] = cloud[:,0:3] / scale\n",
    "    return cloud, sample['next']\n",
    "\n",
    "def get_calib(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])    \n",
    "\n",
    "    all_cams = {}\n",
    "    for cam_str in all_cam_strings:                  \n",
    "        cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "        all_cams[cam_str] = cam\n",
    "    return pointsensor, all_cams\n",
    "\n",
    "def get_sampled_color_image_sphere_from_token_with_calib(sample_token, lidar_sensor, all_cams):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    pc = ColorSamplingPointCloud.from_bw(bw, scale)\n",
    "\n",
    "    for cam_str in all_cam_strings:                  \n",
    "        cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "        im = Image.open(osp.join(dataset_path, cam['filename']))\n",
    "                \n",
    "        # Transform pointcloud into the camera frame\n",
    "        pc = transform_from_pcl_to_cam(nusc, lidar_sensor, all_cams[cam_str], pc)\n",
    "        # Grab the depths (camera frame z axis points away from the camera).\n",
    "        depths = pc.points[2, :]\n",
    "\n",
    "        # Project the points onto the image plane\n",
    "        cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "        intrinsics = np.array(cs_record['camera_intrinsic'])\n",
    "        points, mask = project_pc_on_cam(pc, intrinsics, depths, im)\n",
    "        filtered_points = points[:, mask]\n",
    "        \n",
    "        # Sample the intensity values from the image\n",
    "        # and transform back into the LiDAR frame.\n",
    "        pc = sample_color_from_image(im, pc, mask, points) \n",
    "        pc = transform_from_cam_to_pcl(nusc, lidar_sensor, all_cams[cam_str], pc) \n",
    "    \n",
    "    # Scale back to the original value but only use xyz.\n",
    "    cloud = pc.points.T\n",
    "    cloud[:,0:3] = cloud[:,0:3] / scale\n",
    "    return cloud, sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = chunk1_start\n",
    "end = chunk1_end\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "all_sph_images = []\n",
    "for i in tqdm(range(start, end)):    \n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    pc, next_sample_token = get_sampled_image_sphere_from_token(first_sample_token)        \n",
    "    all_sph_images.append(pc)    \n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "        pc, next_sample_token = get_sampled_image_sphere_from_token(next_sample_token)    \n",
    "        all_sph_images.append(pc)\n",
    "    \n",
    "print(f\"Loading complete. Found {len(all_sph_images)} images.\")\n",
    "print(f\"Computing features now...\")    \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "img_features = process_map(partial(progresser_images, grid=grid), all_sph_images, max_workers=8)\n",
    "\n",
    "filename = f\"{export_ds}/images.npy\"\n",
    "np.save(filename, img_features)\n",
    "print(f\"Wrote sph mono image features to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenes from 283 to 293.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a5690ba1bf4583b88991599e1ac13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete. Found 401 images.\n",
      "It took 151.14681679590086 ms.\n",
      "Computing features now...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8654f256f1f4acea215c9d7d53313ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 225.83812258903524 ms.\n"
     ]
    }
   ],
   "source": [
    "## start = chunk1_start\n",
    "start = chunk2_start\n",
    "end = chunk2_start+10\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "scale = 123\n",
    "all_color_sph_images = []\n",
    "runtime = 0\n",
    "for i in tqdm(range(start, end)):    \n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    lidar_sensor, all_cams = get_calib(first_sample_token)\n",
    "    \n",
    "    pc, next_sample_token = get_sampled_color_image_sphere_from_token(first_sample_token)        \n",
    "    all_color_sph_images.append(pc)    \n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "#         pc, next_sample_token = get_sampled_color_image_sphere_from_token_with_calib(next_sample_token, lidar_sensor, all_cams)    \n",
    "        start_time = time.time() * 1000\n",
    "        pc, next_sample_token = get_sampled_color_image_sphere_from_token(next_sample_token)    \n",
    "        executionTime = (time.time() * 1000 - start_time)\n",
    "        runtime = runtime + executionTime\n",
    "        all_color_sph_images.append(pc)\n",
    "    \n",
    "print(f\"Loading complete. Found {len(all_color_sph_images)} images.\")\n",
    "print(f\"It took {runtime / len(all_color_sph_images)} ms.\")\n",
    "print(f\"Computing features now...\")\n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "\n",
    "start_time = time.time() * 1000\n",
    "color_img_features = process_map(partial(progresser_color_images, grid=grid), all_color_sph_images, max_workers=8, chunksize=100)\n",
    "executionTime = (time.time() * 1000 - start_time)\n",
    "print(f\"It took {executionTime / len(all_color_sph_images)} ms.\")\n",
    "\n",
    "# filename = f\"{export_ds}/color_images_test.npy\"\n",
    "# np.save(filename, color_img_features)\n",
    "# print(f\"Wrote sph color image features to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "cur_color_image = color_img_features[i]\n",
    "cur_color_image = np.reshape(cur_color_image, (3, -1)).T\n",
    "pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "points_xyz = pc.points.T[:,0:3]\n",
    "points_xyzrgb = np.column_stack((points_xyz, cur_color_image[:, 0:3]))\n",
    "visualize_pointcloud(points_xyzrgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pointclouds to spherical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progresser_lidar(sample, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "    sample_sphere = Sphere(sample)\n",
    "    return sample_sphere.sampleUsingGrid(grid, True)\n",
    "\n",
    "def writeRawPointCloud(cloud, filename):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    colors = mapIntensityToRGB(cloud[:, 3])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.io.write_point_cloud(filename, pcd)\n",
    "    \n",
    "def get_data_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    # Load a single lidar point cloud.\n",
    "    pcl_path = osp.join(dataset_path, pointsensor['filename'])\n",
    "    pc = LidarPointCloud.from_file(pcl_path)    \n",
    "    return pc.points.T, sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_point_cloud_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    # Load a single lidar point cloud.\n",
    "    pcl_path = osp.join(dataset_path, pointsensor['filename'])\n",
    "    pc = LidarPointCloud.from_file(pcl_path)\n",
    "    points_xyzi = pc.points.T\n",
    "    \n",
    "    # Load the semantic segmentation.\n",
    "    sample_data_token = sample['data'][lidar_string]\n",
    "    lidarseg_labels_filename = osp.join(nusc.dataroot, nusc.get('lidarseg', sample_data_token)['filename'])\n",
    "    points_label = np.fromfile(lidarseg_labels_filename, dtype=np.uint8)  # [num_points]\n",
    "\n",
    "    # Combine the two.\n",
    "    return np.column_stack((points_xyzi, points_label)), sample['next']\n",
    "\n",
    "def combine_pointclouds(pointclouds, poses):\n",
    "    n_data = len(poses)    \n",
    "    pivot = n_data // 2  \n",
    "    T_G_L_pivot = poses[pivot]\n",
    "    T_L_pivot_G = np.linalg.inv(T_G_L_pivot)\n",
    "\n",
    "    acc_points = pointclouds[pivot]\n",
    "    for i in range(0, n_data):\n",
    "        if i == pivot:\n",
    "            continue\n",
    "        T_G_L = poses[i]\n",
    "        T_L_pivot_L = T_L_pivot_G @ T_G_L\n",
    "\n",
    "        points = Utils.transform_pointcloud(pointclouds[i], T_L_pivot_L)\n",
    "        acc_points = np.append(acc_points, points, axis=0)\n",
    "                        \n",
    "    return acc_points, pivot\n",
    "\n",
    "def combine_every_nth_point_cloud(pointclouds, poses, n=3):\n",
    "    n_poses = len(poses)    \n",
    "    \n",
    "    # Generate combinations.\n",
    "    combined = []\n",
    "    pivot_indices = []\n",
    "    for i in range(0, n_poses, 1):\n",
    "        if i+3 >= n_poses:\n",
    "            break\n",
    "            \n",
    "        indices = np.arange(i, i+3, 1)        \n",
    "        local_clouds = []\n",
    "        local_poses = []\n",
    "        for idx in indices:        \n",
    "            local_clouds.append(pointclouds[idx])\n",
    "            local_poses.append(poses[idx])\n",
    "        acc_points, pivot = combine_pointclouds(local_clouds, local_poses)\n",
    "        combined.append(acc_points)\n",
    "        pivot_indices.append(indices[pivot])\n",
    "    return combined, pivot_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenes from 0 to 283.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456c3d386db0453ab51db0f95137de9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete. Found 11230 clouds.\n",
      "Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce87f4a934e46cdabbf44c933a45fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 116.40371095924004 ms.\n"
     ]
    }
   ],
   "source": [
    "start = chunk1_start\n",
    "end = chunk1_end\n",
    "\n",
    "# start = n_scenes-10\n",
    "# end = n_scenes\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "all_sem_clouds = []\n",
    "for i in tqdm(range(start, end)):\n",
    "    scene_clouds = []\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    pc, next_sample_token = get_semantic_point_cloud_from_token(first_sample_token)\n",
    "    all_sem_clouds.append(pc)\n",
    "    \n",
    "    while next_sample_token != '':            \n",
    "        pc, next_sample_token = get_semantic_point_cloud_from_token(next_sample_token)        \n",
    "        all_sem_clouds.append(pc)   \n",
    "\n",
    "# This is the code for combining/accumulating multiple clouds to one pointcloud\n",
    "# all_pivots = []\n",
    "# for i in tqdm(range(start, end)):\n",
    "#     scene_clouds = []\n",
    "#     scene = nusc.scene[i]\n",
    "#     first_sample_token = scene['first_sample_token']\n",
    "#     pc, next_sample_token = get_semantic_point_cloud_from_token(first_sample_token)\n",
    "#     scene_clouds.append(pc)\n",
    "    \n",
    "#     while next_sample_token != '':    \n",
    "#         pc, next_sample_token = get_semantic_point_cloud_from_token(next_sample_token)    \n",
    "#         scene_clouds.append(pc)   \n",
    "    \n",
    "#     combined_clouds, pivot_indices = combine_every_nth_point_cloud(scene_clouds, all_scene_poses[i], 3)\n",
    "#     all_sem_clouds.append(combined_clouds)\n",
    "#     all_pivots.append(pivot_indices)\n",
    "\n",
    "print(f\"Loading complete. Found {len(all_sem_clouds)} clouds.\")    \n",
    "print(f\"Computing features...\")    \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "\n",
    "start_time = time.time() * 1000\n",
    "sem_features = process_map(partial(progresser_lidar, grid=grid), all_sem_clouds, max_workers=8, chunksize=100)\n",
    "executionTime = (time.time() * 1000 - start_time)\n",
    "print(f\"It took {executionTime / len(all_sem_clouds)} ms.\")\n",
    "\n",
    "# filename = f\"{export_ds}/clouds1.npy\"\n",
    "# np.save(filename, sem_features)\n",
    "# print(f\"Wrote sph cloud features to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 240, 240)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"It took {executionTime / len(all_sem_clouds)} ms.\")\n",
    "n_features = len(sem_features)\n",
    "for i in range(n_features):\n",
    "  sem_features[i] = sem_features[i][[0, 2],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44698834 -0.32775307 -0.28538856  1.         31.        ]\n",
      " [-3.2120266  -0.18916991 -1.8257709  10.         24.        ]]\n",
      "[[-2.7298481  -0.12322364 -1.617994   27.         27.        ]\n",
      " [-2.848908   -0.12197054 -1.5995693  29.         27.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(all_sem_clouds[0][0:2])\n",
    "np.random.shuffle(all_sem_clouds)\n",
    "print(all_sem_clouds[0][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scans = len(all_sem_clouds)\n",
    "n_scans = 1000\n",
    "for i in range(0, n_scans):\n",
    "    filename = f\"{export_ds}/raw/10/scan{i}.npy\"\n",
    "    np.save(filename, all_sem_clouds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4110\n",
    "cur_sem_cloud = sem_features[i]\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "\n",
    "pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "points_xyz = pc.points.T[:,0:3]\n",
    "points_xyzi = np.column_stack((points_xyz, cur_sem_cloud[:,0]))\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:, 2]))\n",
    "\n",
    "visualize_pointcloud(points_xyzi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 21\n",
    "cur_sem_cloud = sem_features[i]\n",
    "# cur_image = img_features[i]\n",
    "cur_color_image = color_img_features[i]\n",
    "\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "# cur_image = np.reshape(cur_image, (1, -1)).T\n",
    "cur_color_image = np.reshape(cur_color_image, (3, -1)).T\n",
    "\n",
    "\n",
    "pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "points_xyz = pc.points.T[:,0:3]\n",
    "points_xyzi = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "# points_xyzp = np.column_stack((points_xyz, cur_image))\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:, 2]))\n",
    "points_xyzrgb = np.column_stack((points_xyz, cur_color_image[:, 0:3]))\n",
    "\n",
    "visualize_pointcloud(points_xyzi)\n",
    "# visualize_pointcloud(points_xyzp)\n",
    "# visualize_pointcloud(points_xyzl)\n",
    "visualize_pointcloud(points_xyzrgb)\n",
    "# visualize_on_top(points_xyzrgb, points_xyzi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write pointclouds\n",
    "write_pointcloud(points_xyzrgb, '/tmp/sph_image.pcd')\n",
    "write_pointcloud(points_xyzi, '/tmp/sph_cloud.pcd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenes from 700 to 850.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45971b9790514d33806c8c6461c27acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We have 6053 clouds in the validation set.\n"
     ]
    }
   ],
   "source": [
    "def get_next_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)    \n",
    "    return sample['next']\n",
    "\n",
    "\n",
    "start = 700\n",
    "end = 850\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "n_clouds = 0\n",
    "for i in tqdm(range(start, end)):\n",
    "    scene_clouds = []\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    next_sample_token = get_next_token(first_sample_token)\n",
    "    n_clouds = n_clouds + 1\n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "        next_sample_token = get_next_token(next_sample_token)    \n",
    "        n_clouds = n_clouds + 1\n",
    "        \n",
    "print(f'We have {n_clouds} clouds in the validation set.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
