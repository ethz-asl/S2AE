{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn import S2Convolution\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from average_meter import AverageMeter\n",
    "from data_source import DataSource\n",
    "from data_splitter import DataSplitter\n",
    "from database_parser import DatabaseParser\n",
    "\n",
    "from loss import ImprovedTripletLoss\n",
    "from mission_indices import MissionIndices\n",
    "from model import Model\n",
    "from sphere import Sphere\n",
    "from training_set import TrainingSet\n",
    "from visualize import Visualize\n",
    "from model_encode_decode_simple import ModelEncodeDecodeSimple\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from s2cnn import so3_near_identity_grid, S2Convolution, s2_near_identity_grid, SO3Convolution, so3_integrate\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(0)\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "\n",
    "bandwidth = 30\n",
    "restore = False\n",
    "n_epochs = 55\n",
    "batch_size = 13\n",
    "num_workers = 32\n",
    "descriptor_size = 256\n",
    "net_input_size = 2 * bandwidth\n",
    "n_features = 3\n",
    "cache = 1\n",
    "n_data = 52\n",
    "\n",
    "#net = ModelEncodeDecodeSimple(bandwidth).cuda()\n",
    "net = ModelEncodeDecodeSimple(bandwidth)\n",
    "v = Visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading missions db from /mnt/data/datasets/Spherical/test_training_data/missions.csv\n",
      "Read    mission_anchor mission_positive mission_negative\n",
      "0      6725..0000       6725..0000       6725..0000\n",
      "1      6725..0000       6725..0000       6725..0000\n",
      "2      4e53..0000       7799..0000       4e53..0000\n",
      "3      4e53..0000       7799..0000       4e53..0000\n",
      "4      4e53..0000       7799..0000       4e53..0000\n",
      "5      4e53..0000       7799..0000       4e53..0000\n",
      "6      4e53..0000       7799..0000       4e53..0000\n",
      "7      4e53..0000       7799..0000       4e53..0000\n",
      "8      4e53..0000       7799..0000       4e53..0000\n",
      "9      4e53..0000       7799..0000       4e53..0000\n",
      "10     4e53..0000       7799..0000       4e53..0000\n",
      "11     4e53..0000       7799..0000       4e53..0000\n",
      "12     4e53..0000       7799..0000       4e53..0000\n",
      "13     4e53..0000       7799..0000       4e53..0000\n",
      "14     4e53..0000       7799..0000       4e53..0000\n",
      "15     4e53..0000       7799..0000       4e53..0000\n",
      "16     4e53..0000       7799..0000       4e53..0000\n",
      "17     4e53..0000       4e53..0000       4e53..0000\n",
      "18     4e53..0000       4e53..0000       4e53..0000\n",
      "19     4e53..0000       4e53..0000       4e53..0000\n",
      "20     4e53..0000       4e53..0000       4e53..0000\n",
      "21     4e53..0000       4e53..0000       4e53..0000\n",
      "22     4e53..0000       4e53..0000       4e53..0000\n",
      "23     4e53..0000       4e53..0000       4e53..0000\n",
      "24     4e53..0000       4e53..0000       4e53..0000\n",
      "25     4e53..0000       4e53..0000       4e53..0000\n",
      "26     4e53..0000       4e53..0000       4e53..0000\n",
      "27     4e53..0000       4e53..0000       4e53..0000\n",
      "28     4e53..0000       4e53..0000       4e53..0000\n",
      "29     4e53..0000       4e53..0000       4e53..0000\n",
      "30     4e53..0000       4e53..0000       4e53..0000\n",
      "31     4e53..0000       4e53..0000       4e53..0000\n",
      "32     4e53..0000       4e53..0000       4e53..0000\n",
      "33     4e53..0000       4e53..0000       4e53..0000\n",
      "34     4e53..0000       4e53..0000       4e53..0000\n",
      "35     4e53..0000       4e53..0000       4e53..0000\n",
      "36     4e53..0000       4e53..0000       4e53..0000\n",
      "37     4e53..0000       4e53..0000       4e53..0000\n",
      "38     4e53..0000       4e53..0000       4e53..0000\n",
      "39     4e53..0000       4e53..0000       4e53..0000\n",
      "40     4e53..0000       4e53..0000       4e53..0000\n",
      "41     4e53..0000       4e53..0000       4e53..0000\n",
      "42     4e53..0000       4e53..0000       4e53..0000\n",
      "43     4e53..0000       4e53..0000       4e53..0000\n",
      "44     4e53..0000       4e53..0000       4e53..0000\n",
      "45     4e53..0000       4e53..0000       4e53..0000\n",
      "46     4e53..0000       4e53..0000       4e53..0000\n",
      "47     4e53..0000       4e53..0000       4e53..0000\n",
      "48     2d2b..0000       2d2b..0000       4e53..0000\n",
      "49     4e53..0000       4e53..0000       4e53..0000\n",
      "50     4e53..0000       2d2b..0000       4e53..0000\n",
      "51     2d2b..0000       4e53..0000       4e53..0000 in total.\n",
      "Read 52 entries.\n",
      "Loading anchors from:\t/mnt/data/datasets/Spherical/test_training_data//training_anchor_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_anchor_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a2d2f760484cf0927914384fad080f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d7bf0fe404dbab1a82ca43e26b213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading positives from:\t/mnt/data/datasets/Spherical/test_training_data//training_positive_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_positive_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e40e9a85514c2a88131c4cf01743ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04746f96c8774acda39a0dc4ce61fc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading negatives from:\t/mnt/data/datasets/Spherical/test_training_data//training_negative_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_negative_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4c4bb812b84ddf9faecdaa62c520af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15695f8004724fa5903d5f4aaa83a480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done loading dataset.\n",
      "\tAnchor point clouds total: \t52\n",
      "\tAnchor images total: \t\t52\n",
      "\tAnchor poses total: \t\t52\n",
      "\tPositive point clouds total: \t52\n",
      "\tPositive images total: \t\t52\n",
      "\tPositive poses total: \t\t52\n",
      "\tNegative point clouds total: \t52\n",
      "\tNegative images total: \t\t52\n",
      "\tNegative poses total: \t\t52\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/mnt/data/datasets/Spherical/test_training_data/\"\n",
    "db_parser = DatabaseParser(dataset_path)\n",
    "\n",
    "ds = DataSource(dataset_path, cache)\n",
    "ds.load(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f170e5dfab154493a7b053d271d74373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating positive spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a28b747f8441dfa9bd1422c87d0eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating negative spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93de53b3543e4a8f853a6d98703ea648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated features\n",
      "a features 370044, p features 371550, n features 368757,\n",
      "Generating features from 0 to 52\n"
     ]
    }
   ],
   "source": [
    "train_set = TrainingSet(restore, bandwidth)\n",
    "train_set.generateAll(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  52\n",
      "Training size:  46\n",
      "Validation size:  6\n",
      "Test size is 0. Configured for external tests\n"
     ]
    }
   ],
   "source": [
    "print(\"Total size: \", len(train_set))\n",
    "split = DataSplitter(train_set, restore, test_train_split=1.0, shuffle=True)\n",
    "\n",
    "train_loader, val_loader, test_loader = split.get_split(\n",
    "    batch_size=batch_size, num_workers=num_workers)\n",
    "train_size = split.get_train_size()\n",
    "val_size = split.get_val_size()\n",
    "test_size = split.get_test_size()\n",
    "print(\"Training size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "if test_size == 0:\n",
    "    print('Test size is 0. Configured for external tests')\n",
    "else:\n",
    "    print(\"Testing size: \", test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor shape is (65536, 4)\n"
     ]
    }
   ],
   "source": [
    "# For the datasource \n",
    "(a, p, n) = ds.get_all_cached_clouds()\n",
    "first_anchor = a[0]\n",
    "print(f\"Anchor shape is {first_anchor.shape}\")\n",
    "v.visualizeRawPointCloud(first_anchor, jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor feature length is 52\n",
      "Anchor feature shape is torch.Size([2, 60, 60])\n",
      "Anchor feature shape is (2, 60, 60)\n",
      "Non zero features: 7200\n"
     ]
    }
   ],
   "source": [
    "# For the train set\n",
    "anchor_features = train_set.anchor_features\n",
    "print(f\"Anchor feature length is {len(anchor_features)}\")\n",
    "anchor_feat, _, _ = train_set.__getitem__(0)\n",
    "print(f\"Anchor feature shape is {anchor_feat.shape}\")\n",
    "anchor_feat = anchor_features[0]\n",
    "print(f\"Anchor feature shape is {anchor_feat.shape}\")\n",
    "print(f\"Non zero features: {np.count_nonzero(anchor_feat)}\")\n",
    "sphere_anchor = Sphere(bw=bandwidth, features=anchor_feat)\n",
    "v.visualizeSphere(sphere_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()                                                                  \n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        #data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()      \n",
    "        data1, data2, data3 = data1.float(), data2.float(), data3.float()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([13, 2, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 13, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "encoded x shape is torch.Size([13, 10, 60, 60, 60])\n",
      "integrated x shape is torch.Size([13, 10, 60, 60])\n",
      "[deconv] x shape is torch.Size([900, 13, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "z shape is torch.Size([10, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 1, 2, 2]' is invalid for input of size 40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-56e8b2984c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"input shape: {data1.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_enc_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"computed embedding: {x_enc_dec.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/workspace/phaser_ws/src/S2AE/src/model_encode_decode_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso3_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"integrated x shape is {x_enc.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconvolutional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, feature, beta, alpha, gamma]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mx_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso3_integrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dec\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_dec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/workspace/phaser_ws/src/S2AE/src/s2_deconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m#yy = s2_mm_inv(y, y, conj_x=True, conj_y=False)  # [l * m * n, batch, feature_out, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m#z = s2_div(x, y, conj_y = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2_mm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfeature_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfeature_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;31m#zy = s2_mm(x, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m#z = s2_div(zy,yy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/workspace/phaser_ws/src/S2AE/src/s2_deconv.py\u001b[0m in \u001b[0;36ms2_mm_2\u001b[0;34m(x, y, nbatch, nfeature_in, nfeature_out, conj_x, conj_y)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mFz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex_mm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconj_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconj_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconj_y\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [m_x * batch, m_y * feature_out, complex] m_x -> m, m_y -> n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mFz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfeature_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [m, batch, n, feature_out, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mFz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [m, n, batch, feature_out, complex]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mFz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 1, 2, 2]' is invalid for input of size 40"
     ]
    }
   ],
   "source": [
    "x_init = torch.clone(data1)\n",
    "print(f\"input shape: {data1.shape}\")\n",
    "x_enc_dec = net(data1)\n",
    "print(f\"computed embedding: {x_enc_dec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features before (2, 60, 60), features after (2, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "features_before = x_init[0,:,:,:].detach().numpy()\n",
    "features_after = x_enc_dec[0,:,:,:].detach().numpy()\n",
    "\n",
    "print(f\"features before {features_before.shape}, features after {features_after.shape}\")\n",
    "sphere_before = Sphere(bw=bandwidth, features=features_before)\n",
    "sphere_after = Sphere(bw=bandwidth, features=features_after)\n",
    "\n",
    "v.visualizeSphere(sphere_before, jupyter=False)\n",
    "#v.visualizeSphere(sphere_after, jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range L2 is 1237.4351806640625 and Intensity L2 is 20686.00390625\n"
     ]
    }
   ],
   "source": [
    "features_diff_range = features_before[0,:,:]-features_after[0,:,:]\n",
    "features_diff_intensity = features_before[1,:,:]-features_after[1,:,:]\n",
    "\n",
    "range_l2 = np.linalg.norm(features_diff_range, ord=2)\n",
    "intensity_l2 = np.linalg.norm(features_diff_intensity, ord=2)\n",
    "\n",
    "print(f\"Range L2 is {range_l2} and Intensity L2 is {intensity_l2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
