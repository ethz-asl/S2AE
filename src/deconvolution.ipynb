{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconvolution Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn import S2Convolution\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from average_meter import AverageMeter\n",
    "from data_source import DataSource\n",
    "from data_splitter import DataSplitter\n",
    "from database_parser import DatabaseParser\n",
    "\n",
    "from loss import ImprovedTripletLoss\n",
    "from mission_indices import MissionIndices\n",
    "from model import Model\n",
    "from sphere import Sphere\n",
    "from training_set import TrainingSet\n",
    "from visualize import Visualize\n",
    "from model_encode_decode_simple import ModelEncodeDecodeSimple\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from s2cnn import so3_near_identity_grid, S2Convolution, s2_near_identity_grid, SO3Convolution, so3_integrate\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(0)\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "\n",
    "bandwidth = 30\n",
    "restore = False\n",
    "n_epochs = 55\n",
    "batch_size = 13\n",
    "num_workers = 32\n",
    "descriptor_size = 256\n",
    "net_input_size = 2 * bandwidth\n",
    "n_features = 3\n",
    "cache = 1\n",
    "n_data = 52\n",
    "\n",
    "#net = ModelEncodeDecodeSimple(bandwidth).cuda()\n",
    "net = ModelEncodeDecodeSimple(bandwidth)\n",
    "v = Visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading missions db from /mnt/data/datasets/Spherical/test_training_data/missions.csv\n",
      "Read    mission_anchor mission_positive mission_negative\n",
      "0      6725..0000       6725..0000       6725..0000\n",
      "1      6725..0000       6725..0000       6725..0000\n",
      "2      4e53..0000       7799..0000       4e53..0000\n",
      "3      4e53..0000       7799..0000       4e53..0000\n",
      "4      4e53..0000       7799..0000       4e53..0000\n",
      "5      4e53..0000       7799..0000       4e53..0000\n",
      "6      4e53..0000       7799..0000       4e53..0000\n",
      "7      4e53..0000       7799..0000       4e53..0000\n",
      "8      4e53..0000       7799..0000       4e53..0000\n",
      "9      4e53..0000       7799..0000       4e53..0000\n",
      "10     4e53..0000       7799..0000       4e53..0000\n",
      "11     4e53..0000       7799..0000       4e53..0000\n",
      "12     4e53..0000       7799..0000       4e53..0000\n",
      "13     4e53..0000       7799..0000       4e53..0000\n",
      "14     4e53..0000       7799..0000       4e53..0000\n",
      "15     4e53..0000       7799..0000       4e53..0000\n",
      "16     4e53..0000       7799..0000       4e53..0000\n",
      "17     4e53..0000       4e53..0000       4e53..0000\n",
      "18     4e53..0000       4e53..0000       4e53..0000\n",
      "19     4e53..0000       4e53..0000       4e53..0000\n",
      "20     4e53..0000       4e53..0000       4e53..0000\n",
      "21     4e53..0000       4e53..0000       4e53..0000\n",
      "22     4e53..0000       4e53..0000       4e53..0000\n",
      "23     4e53..0000       4e53..0000       4e53..0000\n",
      "24     4e53..0000       4e53..0000       4e53..0000\n",
      "25     4e53..0000       4e53..0000       4e53..0000\n",
      "26     4e53..0000       4e53..0000       4e53..0000\n",
      "27     4e53..0000       4e53..0000       4e53..0000\n",
      "28     4e53..0000       4e53..0000       4e53..0000\n",
      "29     4e53..0000       4e53..0000       4e53..0000\n",
      "30     4e53..0000       4e53..0000       4e53..0000\n",
      "31     4e53..0000       4e53..0000       4e53..0000\n",
      "32     4e53..0000       4e53..0000       4e53..0000\n",
      "33     4e53..0000       4e53..0000       4e53..0000\n",
      "34     4e53..0000       4e53..0000       4e53..0000\n",
      "35     4e53..0000       4e53..0000       4e53..0000\n",
      "36     4e53..0000       4e53..0000       4e53..0000\n",
      "37     4e53..0000       4e53..0000       4e53..0000\n",
      "38     4e53..0000       4e53..0000       4e53..0000\n",
      "39     4e53..0000       4e53..0000       4e53..0000\n",
      "40     4e53..0000       4e53..0000       4e53..0000\n",
      "41     4e53..0000       4e53..0000       4e53..0000\n",
      "42     4e53..0000       4e53..0000       4e53..0000\n",
      "43     4e53..0000       4e53..0000       4e53..0000\n",
      "44     4e53..0000       4e53..0000       4e53..0000\n",
      "45     4e53..0000       4e53..0000       4e53..0000\n",
      "46     4e53..0000       4e53..0000       4e53..0000\n",
      "47     4e53..0000       4e53..0000       4e53..0000\n",
      "48     2d2b..0000       2d2b..0000       4e53..0000\n",
      "49     4e53..0000       4e53..0000       4e53..0000\n",
      "50     4e53..0000       2d2b..0000       4e53..0000\n",
      "51     2d2b..0000       4e53..0000       4e53..0000 in total.\n",
      "Read 52 entries.\n",
      "Loading anchors from:\t/mnt/data/datasets/Spherical/test_training_data//training_anchor_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_anchor_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3bf9ec9735404e83d454ac368ff0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a645c30c75f4e4a876d2e05fa571b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading positives from:\t/mnt/data/datasets/Spherical/test_training_data//training_positive_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_positive_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de96c414e4c44e3a9ae8041cbd054f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ba7960b56143c994bd6558bc4acd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading negatives from:\t/mnt/data/datasets/Spherical/test_training_data//training_negative_pointclouds/ and /mnt/data/datasets/Spherical/test_training_data//training_negative_sph_images/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb41d96d3b7a44a4b28ce9b39adb9f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b356548880c54c2f815fa497f9ba205e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done loading dataset.\n",
      "\tAnchor point clouds total: \t52\n",
      "\tAnchor images total: \t\t52\n",
      "\tAnchor poses total: \t\t52\n",
      "\tPositive point clouds total: \t52\n",
      "\tPositive images total: \t\t52\n",
      "\tPositive poses total: \t\t52\n",
      "\tNegative point clouds total: \t52\n",
      "\tNegative images total: \t\t52\n",
      "\tNegative poses total: \t\t52\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/mnt/data/datasets/Spherical/test_training_data/\"\n",
    "db_parser = DatabaseParser(dataset_path)\n",
    "\n",
    "ds = DataSource(dataset_path, cache)\n",
    "ds.load(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a09c4d062d54c9d8e71a84b2dc2808a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating positive spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac6be1eed77471fb866f31c062504ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating negative spheres\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cab455adb0d465d97315e15cbeeaf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated features\n",
      "a features 370044, p features 371550, n features 368757,\n",
      "Generating features from 0 to 52\n"
     ]
    }
   ],
   "source": [
    "train_set = TrainingSet(restore, bandwidth)\n",
    "train_set.generateAll(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  52\n",
      "Training size:  46\n",
      "Validation size:  6\n",
      "Test size is 0. Configured for external tests\n"
     ]
    }
   ],
   "source": [
    "print(\"Total size: \", len(train_set))\n",
    "split = DataSplitter(train_set, restore, test_train_split=1.0, shuffle=True)\n",
    "\n",
    "train_loader, val_loader, test_loader = split.get_split(\n",
    "    batch_size=batch_size, num_workers=num_workers)\n",
    "train_size = split.get_train_size()\n",
    "val_size = split.get_val_size()\n",
    "test_size = split.get_test_size()\n",
    "print(\"Training size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "if test_size == 0:\n",
    "    print('Test size is 0. Configured for external tests')\n",
    "else:\n",
    "    print(\"Testing size: \", test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor shape is (65536, 4)\n"
     ]
    }
   ],
   "source": [
    "# For the datasource \n",
    "(a, p, n) = ds.get_all_cached_clouds()\n",
    "first_anchor = a[0]\n",
    "print(f\"Anchor shape is {first_anchor.shape}\")\n",
    "v.visualizeRawPointCloud(first_anchor, jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor feature length is 52\n",
      "Anchor feature shape is torch.Size([2, 60, 60])\n",
      "Anchor feature shape is (2, 60, 60)\n",
      "Non zero features: 7200\n"
     ]
    }
   ],
   "source": [
    "# For the train set\n",
    "anchor_features = train_set.anchor_features\n",
    "print(f\"Anchor feature length is {len(anchor_features)}\")\n",
    "anchor_feat, _, _ = train_set.__getitem__(0)\n",
    "print(f\"Anchor feature shape is {anchor_feat.shape}\")\n",
    "anchor_feat = anchor_features[0]\n",
    "print(f\"Anchor feature shape is {anchor_feat.shape}\")\n",
    "print(f\"Non zero features: {np.count_nonzero(anchor_feat)}\")\n",
    "sphere_anchor = Sphere(bw=bandwidth, features=anchor_feat)\n",
    "v.visualizeSphere(sphere_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()                                                                  \n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        #data1, data2, data3 = data1.cuda().float(), data2.cuda().float(), data3.cuda().float()      \n",
    "        data1, data2, data3 = data1.float(), data2.float(), data3.float()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([13, 2, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 13, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "encoded x shape is torch.Size([13, 10, 60, 60, 60])\n",
      "computed embedding: torch.Size([13, 10, 60, 60, 60])\n"
     ]
    }
   ],
   "source": [
    "x_init = torch.clone(data1)\n",
    "print(f\"input shape: {data1.shape}\")\n",
    "x_enc_dec = net(data1)\n",
    "print(f\"computed embedding: {x_enc_dec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features before (2, 60, 60), features after (2, 60, 60)\n",
      "before non zero: 7179 after non zero: 7200\n"
     ]
    }
   ],
   "source": [
    "features_before = x_init[0,:,:,:].detach().numpy()\n",
    "features_after = x_enc_dec[0,:,:,:].detach().numpy()\n",
    "\n",
    "print(f\"features before {features_before.shape}, features after {features_after.shape}\")\n",
    "sphere_before = Sphere(bw=bandwidth, features=features_before)\n",
    "sphere_after = Sphere(bw=bandwidth, features=features_after)\n",
    "\n",
    "#v.visualizeSphere(sphere_before, jupyter=False)\n",
    "v.visualizeSphere(sphere_after, jupyter=False)\n",
    "print(f\"before non zero: {np.count_nonzero(features_before)} after non zero: {np.count_nonzero(features_after)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range L2 is 1224.90478515625 and Intensity L2 is 21150.828125\n"
     ]
    }
   ],
   "source": [
    "features_diff_range = features_before[0,:,:]-np.nan_to_num(features_after[0,:,:])\n",
    "features_diff_intensity = features_before[1,:,:]-np.nan_to_num(features_after[1,:,:])\n",
    "\n",
    "range_l2 = np.linalg.norm(features_diff_range, ord=2)\n",
    "intensity_l2 = np.linalg.norm(features_diff_intensity, ord=2)\n",
    "\n",
    "print(f\"Range L2 is {range_l2} and Intensity L2 is {intensity_l2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_n: tensor([[ 0.2000,  0.4000],\n",
      "        [ 0.3000, -0.1000]]) \n",
      "a_n2: tensor([[ 0.2000,  0.4000],\n",
      "        [ 0.3000, -0.1000]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor((1 +2j, 3 - 1j))\n",
    "a_eng = a.abs() * a.abs()\n",
    "a_n = torch.div(a, a_eng)\n",
    "a_n2 = a / a_eng\n",
    "print(f\"a_n: {torch.view_as_real(a_n)} \\na_n2: {torch.view_as_real(a_n2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"first: {x_enc_dec.size()} second {x_enc_dec.size()[:-1]}\")\n",
    "x = torch.sum(x_enc_dec, dim=-1)\n",
    "print(f\"sum: {x.size()}\")\n",
    "x = x_enc_dec\n",
    "test = x.view(x.size(0), x.size(1), x.size(2), x.size(3), -1).max(-1)[0]\n",
    "test2 = x.view(x.size(0), x.size(1), x.size(2), x.size(3), -1)\n",
    "test3 = x.max(-1)[0]\n",
    "#x = x.view(x.size(0), x.size(1), -1).max(-1)[0]  # [batch, feature]\n",
    "print(f\"test size is {test.size()} and test2 is {test2.size()} and test3 is {test3.size()}\")\n",
    "\n",
    "features = test3.detach().numpy()\n",
    "sphere = Sphere(bw=bandwidth, features=features)\n",
    "v.visualizeSphere(sphere, jupyter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape is torch.Size([2, 3, 2]), a_1 is torch.Size([2, 3]) and a_2 is torch.Size([2, 3])\n",
      "B shape is torch.Size([2, 3])\n",
      "B is\n",
      "tensor([[9., 7., 3.],\n",
      "        [5., 8., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones([2, 3,2], dtype=torch.float64)\n",
    "a_1 = torch.tensor(np.array([[3,7,1],[5,8,2]]))\n",
    "a_2 = torch.tensor(np.array([[9,1,3],[4,3,0]]))\n",
    "print(f\"A shape is {A.size()}, a_1 is {a_1.size()} and a_2 is {a_2.size()}\")\n",
    "A[:,:,0] = a_1\n",
    "A[:,:,1] = a_2\n",
    "\n",
    "B = A.max(-1)[0]\n",
    "print(f\"B shape is {B.size()}\")\n",
    "print(f\"B is\\n{B}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
