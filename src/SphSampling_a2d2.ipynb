{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampled Dataset of A2D2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from matplotlib import cm\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from sphere import Sphere\n",
    "from dh_grid import DHGrid\n",
    "from laserscan import SemLaserScan\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from os.path import join\n",
    "import glob\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 elements in the folder.\n"
     ]
    }
   ],
   "source": [
    "dataroot = '/media/berlukas/Data/data/datasets/s2ae/a2d2/'\n",
    "# dataroot = '/media/berlukas/Data/data/datasets/s2ae/a2d2-preview'\n",
    "sequences = f'{dataroot}/sequences'\n",
    "export_ds = f'{dataroot}/processed'\n",
    "segments = os.listdir(sequences)\n",
    "sensors = ['cam_front_center', 'cam_front_left', 'cam_front_right', 'cam_rear_center', 'cam_side_left', 'cam_side_right']\n",
    "# sensors = ['cam_front_center']\n",
    "\n",
    "with open (f'{dataroot}/cams_lidars.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "with open (f'{dataroot}/class_list.json', 'r') as f:\n",
    "    class_list = json.load(f)\n",
    "\n",
    "print(f'Found {len(segments)} elements in the folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2252 clouds for cam_front_center.\n",
      "Found 504 clouds for cam_front_left.\n",
      "Found 508 clouds for cam_front_right.\n",
      "Found 444 clouds for cam_rear_center.\n",
      "Found 433 clouds for cam_side_left.\n",
      "Found 426 clouds for cam_side_right.\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    root_path = f'{sequences}/{segment}/lidar'\n",
    "    lidar_files = {}\n",
    "    for lidar in sensors:\n",
    "        sensor_path = f'{root_path}/{lidar}/*.npz'                \n",
    "        lidar_files[lidar] = sorted(glob.glob(sensor_path))\n",
    "        print(f'Found {len(lidar_files[lidar])} clouds for {lidar}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_front_center\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec8bf24da9c4988b9c79f2dcb208e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_front_left\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b573c497e244746ba7b182a7e785102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_front_right\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3bddb870be4c019d27c6bf4aea35f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_rear_center\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2688d3177a45d1b42ac087a4b3724c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_side_left\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98429a47e98a4ce796a6ffb5b79b406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_side_right\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07db7ab782214a5dacef71fc7f185de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4567 pointclouds\n"
     ]
    }
   ],
   "source": [
    "def undistort_image(image, cam_name):\n",
    "    if cam_name in ['front_left', 'front_center', \\\n",
    "                    'front_right', 'side_left', \\\n",
    "                    'side_right', 'rear_center']:\n",
    "        # get parameters from config file\n",
    "        intr_mat_undist = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['CamMatrix'])\n",
    "        intr_mat_dist = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['CamMatrixOriginal'])\n",
    "        dist_parms = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['Distortion'])\n",
    "        lens = config['cameras'][cam_name]['Lens']\n",
    "        \n",
    "        if (lens == 'Fisheye'):\n",
    "            return cv2.fisheye.undistortImage(image, intr_mat_dist,\\\n",
    "                                      D=dist_parms, Knew=intr_mat_undist)\n",
    "        elif (lens == 'Telecam'):\n",
    "            return cv2.undistort(image, intr_mat_dist, \\\n",
    "                      distCoeffs=dist_parms, newCameraMatrix=intr_mat_undist)\n",
    "        else:\n",
    "            return image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def extract_semantic_file_name_from_image_file_name(file_name_image):\n",
    "    file_name_semantic_label = file_name_image.split('/')\n",
    "    file_name_semantic_label = file_name_semantic_label[-1].split('.')[0]    \n",
    "    file_name_semantic_label = file_name_semantic_label.split('_')\n",
    "    file_name_semantic_label = file_name_semantic_label[0] + '_' + \\\n",
    "                  'label_' + \\\n",
    "                  file_name_semantic_label[2] + '_' + \\\n",
    "                  file_name_semantic_label[3] + '.png'    \n",
    "    return file_name_semantic_label\n",
    "\n",
    "def create_open3d_pc(lidar, cam_image=None):\n",
    "    # create open3d point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # assign point coordinates\n",
    "    pcd.points = o3d.utility.Vector3dVector(lidar['points'])\n",
    "    \n",
    "    # assign colours\n",
    "    if cam_image is None:\n",
    "        median_reflectance = np.median(lidar['reflectance'])\n",
    "        colours = colours_from_reflectances(lidar['reflectance']) / (median_reflectance * 5)\n",
    "        \n",
    "        # clip colours for visualisation on a white background\n",
    "        colours = np.clip(colours, 0, 0.75)\n",
    "    else:\n",
    "        rows = (lidar['row'] + 0.5).astype(np.int)\n",
    "        cols = (lidar['col'] + 0.5).astype(np.int)\n",
    "        colours = cam_image[rows, cols, :] / 255.0\n",
    "        \n",
    "    pcd.colors = o3d.utility.Vector3dVector(colours)    \n",
    "    return pcd\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "\n",
    "def map_name_to_label(name):\n",
    "    if name == 'Car 1':\n",
    "        return 0\n",
    "    if name == 'Car 2':\n",
    "        return 1\n",
    "    if name == 'Car 3':\n",
    "        return 2\n",
    "    if name == 'Car 4':\n",
    "        return 3    \n",
    "    if name == 'Bicycle 1':\n",
    "        return 4\n",
    "    if name == 'Bicycle 2':\n",
    "        return 5\n",
    "    if name == 'Bicycle 3':\n",
    "        return 6\n",
    "    if name == 'Bicycle 4':\n",
    "        return 7    \n",
    "    if name == 'Pedestrian 1':\n",
    "        return 8\n",
    "    if name == 'Pedestrian 2':\n",
    "        return 9\n",
    "    if name == 'Pedestrian 3':\n",
    "        return 10\n",
    "    if name == 'Truck 1':\n",
    "        return 11\n",
    "    if name == 'Truck 2':\n",
    "        return 12\n",
    "    if name == 'Truck 3':\n",
    "        return 13    \n",
    "    if name == 'Small vehicles 1':\n",
    "        return 14\n",
    "    if name == 'Small vehicles 2':\n",
    "        return 15\n",
    "    if name == 'Small vehicles 3':\n",
    "        return 16    \n",
    "    if name == 'Traffic signal 1':\n",
    "        return 17\n",
    "    if name == 'Traffic signal 2':\n",
    "        return 18\n",
    "    if name == 'Traffic signal 3':\n",
    "        return 19    \n",
    "    if name == 'Traffic sign 1':\n",
    "        return 20\n",
    "    if name == 'Traffic sign 2':\n",
    "        return 21\n",
    "    if name == 'Traffic sign 3':\n",
    "        return 22\n",
    "    if name == 'Utility vehicle 1':\n",
    "        return 23\n",
    "    if name == 'Utility vehicle 2':\n",
    "        return 24    \n",
    "    if name == 'Sidebars':\n",
    "        return 25    \n",
    "    if name == 'Speed bumper':\n",
    "        return 26    \n",
    "    if name == 'Curbstone':\n",
    "        return 27    \n",
    "    if name == 'Solid line':\n",
    "        return 28    \n",
    "    if name == 'Irrelevant signs':\n",
    "        return 29    \n",
    "    if name == 'Road blocks':\n",
    "        return 30    \n",
    "    if name == 'Tractor':\n",
    "        return 31\n",
    "    if name == 'Non-drivable street':\n",
    "        return 32\n",
    "    if name == 'Zebra crossing':\n",
    "        return 33\n",
    "    if name == 'Obstacles / trash':\n",
    "        return 34\n",
    "    if name == 'Poles':\n",
    "        return 35\n",
    "    if name == 'RD restricted area':\n",
    "        return 36\n",
    "    if name == 'Animals':\n",
    "        return 37\n",
    "    if name == 'Grid structure':\n",
    "        return 38\n",
    "    if name == 'Signal corpus':\n",
    "        return 39\n",
    "    if name == 'Drivable cobblestone':\n",
    "        return 40\n",
    "    if name == 'Electronic traffic':\n",
    "        return 41    \n",
    "    if name == 'Slow drive area':\n",
    "        return 42\n",
    "    if name == 'Nature object':\n",
    "        return 43\n",
    "    if name == 'Parking area':\n",
    "        return 44\n",
    "    if name == 'Sidewalk':\n",
    "        return 45\n",
    "    if name == 'Ego car':\n",
    "        return 46\n",
    "    if name == 'Painted driv. instr.':\n",
    "        return 47\n",
    "    if name == 'Traffic guide obj.':\n",
    "        return 48\n",
    "    if name == 'Dashed line':\n",
    "        return 49    \n",
    "    if name == 'RD normal street':\n",
    "        return 50\n",
    "    if name == 'Sky':\n",
    "        return 51\n",
    "    if name == 'Buildings':\n",
    "        return 52\n",
    "    if name == 'Blurred area':\n",
    "        return 53\n",
    "    if name == 'Rain dirt':\n",
    "        return 54\n",
    "    print(f'Have an unknown name: {name} !!!')\n",
    "    return 0\n",
    "    \n",
    "def map_colors_to_label(colors):\n",
    "    labels_list = []\n",
    "    for label in colors:\n",
    "        hex_color = rgb_to_hex(tuple(label))\n",
    "        if hex_color not in class_list.keys():\n",
    "            # undefined category\n",
    "            # print(f'Have an unknown color {hex_color}')\n",
    "            labels_list.append(0)\n",
    "        else:\n",
    "            labels_list.append(map_name_to_label(class_list[hex_color]))\n",
    "    return np.array(labels_list)\n",
    "\n",
    "def get_pointcloud_at(lidar, semantic_image):           \n",
    "    # xyz and intensity\n",
    "    points = lidar['points']\n",
    "    intensity = lidar['reflectance']\n",
    "    \n",
    "    # semantic labels from the image\n",
    "    rows = (lidar['row'] + 0.5).astype(int)\n",
    "    cols = (lidar['col'] + 0.5).astype(int)\n",
    "    colors = semantic_image[rows, cols, :]\n",
    "    labels = map_colors_to_label(colors)\n",
    "    \n",
    "    pc = np.column_stack((points, intensity, labels))\n",
    "    return pc\n",
    "\n",
    "  \n",
    "n_sensors = len(sensors)\n",
    "all_sem_clouds = []\n",
    "for sensor in sensors:\n",
    "    print(f'Processing files for sensor: {sensor}')\n",
    "    for file_name_lidar in tqdm(lidar_files[sensor]):\n",
    "        lidar = np.load(file_name_lidar)\n",
    "        \n",
    "        seq_name = file_name_lidar.split('/')[-4]        \n",
    "        file_name_semantic_label = extract_semantic_file_name_from_image_file_name(file_name_lidar)\n",
    "        file_name_semantic_label = join(sequences, seq_name, f'label/{sensor}/', file_name_semantic_label)        \n",
    "        semantic_image = cv2.imread(file_name_semantic_label, cv2.IMREAD_UNCHANGED)                        \n",
    "        semantic_image = cv2.cvtColor(semantic_image, cv2.COLOR_BGR2RGB)        \n",
    "        semantic_image_undistorted = undistort_image(semantic_image, sensor[4:])\n",
    "        pc = get_pointcloud_at(lidar, semantic_image_undistorted)\n",
    "        all_sem_clouds.append(pc)        \n",
    "        \n",
    "print(f'Found {len(all_sem_clouds)} pointclouds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/function_base.py:804: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, order=order, subok=subok, copy=True)\n"
     ]
    }
   ],
   "source": [
    "clouds_cpy = np.copy(all_sem_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sem_clouds = np.copy(clouds_cpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(all_sem_clouds)\n",
    "all_sem_clouds = all_sem_clouds[3300:3800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691adeedcd094d88851471a3cc4a971a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote features to /media/berlukas/Data/data/datasets/s2ae/a2d2//processed/clouds.npy.\n",
      "Saved clouds to /media/berlukas/Data/data/datasets/s2ae/a2d2//processed/archive.npy\n"
     ]
    }
   ],
   "source": [
    "def progresser(sample_idx, grid, auto_position=True, write_safe=False, blocking=True, progress=False):\n",
    "    sample = all_sem_clouds[sample_idx]\n",
    "    sample_sphere = Sphere(sample)\n",
    "    features = sample_sphere.sampleUsingGrid(grid)\n",
    "    return features\n",
    "\n",
    "bw = 50\n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "print(f\"Loading complete. Computing features...\")\n",
    "# parallel\n",
    "sem_idx = np.arange(0, len(all_sem_clouds))\n",
    "sample_func = partial(progresser, grid=grid)\n",
    "sem_features = process_map(sample_func, sem_idx, max_workers=16)            \n",
    "\n",
    "filename = f\"{export_ds}/clouds.npy\"\n",
    "np.save(filename, sem_features)\n",
    "print(f\"Wrote features to {filename}.\")\n",
    "\n",
    "filename = f'archive'\n",
    "np.save(f'{export_ds}/{filename}.npy', all_sem_clouds)\n",
    "print(f'Saved clouds to {export_ds}/{filename}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize extracted pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def visualizeRawPointcloud(pcl, val):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcl[:, 0:3])\n",
    "    colors = mapIntensityToRGB(val)\n",
    "#     colors = scan.sem_color_lut[pcl[:,4].astype(np.int)]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.visualization.draw_geometries([pcd], width=640,  height=480)    \n",
    "    \n",
    "def createGrid_old(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([n_grid * n_grid, 2])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])\n",
    "    return cart_grid\n",
    "\n",
    "def create_sampling_sphere(bw):\n",
    "    grid = createGrid_old(bw)\n",
    "    xyz_grid = convertGridToEuclidean_old(grid)\n",
    "    intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "    sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "    return sampling_grid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = all_sem_clouds[110]\n",
    "visualizeRawPointcloud(pc, pc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have these classes: [ 0.  1.  2.  8.  9. 20. 27. 29. 34. 35. 39. 43. 45. 48. 50. 51. 52.]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(pc[:, 4])\n",
    "print(f'we have these classes: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_sem_cloud = sem_features[110]\n",
    "\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "pc = create_sampling_sphere(bw)\n",
    "points_xyz = pc.T[:,0:3]\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "\n",
    "visualizeRawPointcloud(points_xyzl, points_xyzl[:, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
