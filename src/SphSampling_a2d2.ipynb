{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampled Dataset of A2D2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from matplotlib import cm\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from sphere import Sphere\n",
    "from dh_grid import DHGrid\n",
    "from laserscan import SemLaserScan\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from os.path import join\n",
    "import glob\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 elements in the folder.\n"
     ]
    }
   ],
   "source": [
    "dataroot = '/media/berlukas/Data/jd/camera lidar semantic'\n",
    "sequences = f'{dataroot}/sequences'\n",
    "export_ds = f'{dataroot}/processed'\n",
    "segments = os.listdir(sequences)\n",
    "sensors = ['cam_front_center', 'cam_front_left', 'cam_front_right', 'cam_rear_center', 'cam_side_left', 'cam_side_right']\n",
    "# sensors = ['cam_front_center']\n",
    "\n",
    "with open (f'{dataroot}/cams_lidars.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f'Found {len(segments)} elements in the folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in segments:\n",
    "    root_path = f'{sequences}/{segment}/lidar'\n",
    "    lidar_files = {}\n",
    "    for lidar in sensors:\n",
    "        sensor_path = f'{root_path}/{lidar}/*.npz'                \n",
    "        lidar_files[lidar] = sorted(glob.glob(sensor_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files for sensor: cam_front_center\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f976a5da73794de195ca44e97ac91aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def undistort_image(image, cam_name):\n",
    "    if cam_name in ['front_left', 'front_center', \\\n",
    "                    'front_right', 'side_left', \\\n",
    "                    'side_right', 'rear_center']:\n",
    "        # get parameters from config file\n",
    "        intr_mat_undist = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['CamMatrix'])\n",
    "        intr_mat_dist = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['CamMatrixOriginal'])\n",
    "        dist_parms = \\\n",
    "                  np.asarray(config['cameras'][cam_name]['Distortion'])\n",
    "        lens = config['cameras'][cam_name]['Lens']\n",
    "        \n",
    "        if (lens == 'Fisheye'):\n",
    "            return cv2.fisheye.undistortImage(image, intr_mat_dist,\\\n",
    "                                      D=dist_parms, Knew=intr_mat_undist)\n",
    "        elif (lens == 'Telecam'):\n",
    "            return cv2.undistort(image, intr_mat_dist, \\\n",
    "                      distCoeffs=dist_parms, newCameraMatrix=intr_mat_undist)\n",
    "        else:\n",
    "            return image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def extract_semantic_file_name_from_image_file_name(file_name_image):\n",
    "    file_name_semantic_label = file_name_image.split('/')\n",
    "    file_name_semantic_label = file_name_semantic_label[-1].split('.')[0]    \n",
    "    file_name_semantic_label = file_name_semantic_label.split('_')\n",
    "    file_name_semantic_label = file_name_semantic_label[0] + '_' + \\\n",
    "                  'label_' + \\\n",
    "                  file_name_semantic_label[2] + '_' + \\\n",
    "                  file_name_semantic_label[3] + '.png'    \n",
    "    return file_name_semantic_label\n",
    "\n",
    "def create_open3d_pc(lidar, cam_image=None):\n",
    "    # create open3d point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    # assign point coordinates\n",
    "    pcd.points = o3d.utility.Vector3dVector(lidar['points'])\n",
    "    \n",
    "    # assign colours\n",
    "    if cam_image is None:\n",
    "        median_reflectance = np.median(lidar['reflectance'])\n",
    "        colours = colours_from_reflectances(lidar['reflectance']) / (median_reflectance * 5)\n",
    "        \n",
    "        # clip colours for visualisation on a white background\n",
    "        colours = np.clip(colours, 0, 0.75)\n",
    "    else:\n",
    "        rows = (lidar['row'] + 0.5).astype(np.int)\n",
    "        cols = (lidar['col'] + 0.5).astype(np.int)\n",
    "        colours = cam_image[rows, cols, :] / 255.0\n",
    "        \n",
    "    pcd.colors = o3d.utility.Vector3dVector(colours)    \n",
    "    return pcd\n",
    "\n",
    "def get_pointcloud_at(lidar, semantic_image):           \n",
    "    # xyz and intensity\n",
    "    points = lidar['points']\n",
    "    intensity = lidar['reflectance']\n",
    "    \n",
    "    # semantic labels from the image\n",
    "    rows = (lidar['row'] + 0.5).astype(int)\n",
    "    cols = (lidar['col'] + 0.5).astype(int)\n",
    "    labels = semantic_image[rows, cols, :] / 255.0\n",
    "    \n",
    "    pc = np.column_stack((points, intensity, labels))\n",
    "    return pc\n",
    "\n",
    "n_sensors = len(sensors)\n",
    "all_sem_clouds = []\n",
    "for sensor in sensors:\n",
    "    print(f'Processing files for sensor: {sensor}')\n",
    "    for file_name_lidar in tqdm(lidar_files[sensor]):\n",
    "        lidar = np.load(file_name_lidar)\n",
    "        \n",
    "        seq_name = file_name_lidar.split('/')[-4]        \n",
    "        file_name_semantic_label = extract_semantic_file_name_from_image_file_name(file_name_lidar)\n",
    "        file_name_semantic_label = join(sequences, seq_name, f'label/{sensor}/', file_name_semantic_label)        \n",
    "        semantic_image = cv2.imread(file_name_semantic_label)                \n",
    "        semantic_image_undistorted = undistort_image(semantic_image, sensor[4:])\n",
    "        pc = get_pointcloud_at(lidar, semantic_image_undistorted)\n",
    "        all_sem_clouds.append(pc)\n",
    "        \n",
    "print(f'Found {len(all_sem_clouds)} pointclouds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671e2bc20e154610a68e032e86bab4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote features to /media/berlukas/Data/jd/camera lidar semantic/processed/clouds.npy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clouds to /media/berlukas/Data/jd/camera lidar semantic/processed/archive.npy\n"
     ]
    }
   ],
   "source": [
    "def progresser(sample_idx, grid, auto_position=True, write_safe=False, blocking=True, progress=False):\n",
    "    sample = all_sem_clouds[sample_idx]\n",
    "    sample_sphere = Sphere(sample)\n",
    "    features = sample_sphere.sampleUsingGrid(grid)\n",
    "    return features\n",
    "\n",
    "bw = 50\n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "print(f\"Loading complete. Computing features...\")\n",
    "# parallel\n",
    "sem_idx = np.arange(0, len(all_sem_clouds))\n",
    "sample_func = partial(progresser, grid=grid)\n",
    "sem_features = process_map(sample_func, sem_idx, max_workers=16)            \n",
    "\n",
    "filename = f\"{export_ds}/clouds.npy\"\n",
    "np.save(filename, sem_features)\n",
    "print(f\"Wrote features to {filename}.\")\n",
    "\n",
    "filename = f'archive'\n",
    "np.save(f'{export_ds}/{filename}.npy', all_sem_clouds)\n",
    "print(f'Saved clouds to {export_ds}/{filename}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize extracted pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def visualizeRawPointcloud(pcl, val):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcl[:, 0:3])\n",
    "    colors = mapIntensityToRGB(val)\n",
    "#     colors = scan.sem_color_lut[pcl[:,4].astype(np.int)]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.visualization.draw_geometries([pcd])    \n",
    "    \n",
    "def createGrid_old(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([n_grid * n_grid, 2])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])\n",
    "    return cart_grid\n",
    "\n",
    "def create_sampling_sphere(bw):\n",
    "    grid = createGrid_old(bw)\n",
    "    xyz_grid = convertGridToEuclidean_old(grid)\n",
    "    intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "    sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "    return sampling_grid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = all_sem_clouds[490]\n",
    "visualizeRawPointcloud(pc, pc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_sem_cloud = sem_features[144]\n",
    "\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "pc = create_sampling_sphere(bw)\n",
    "points_xyz = pc.T[:,0:3]\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "\n",
    "visualizeRawPointcloud(points_xyzl, points_xyzl[:, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
