{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPH Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "from nuscenes.utils.data_classes import PointCloud, LidarPointCloud, RadarPointCloud, Box\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from matplotlib import cm\n",
    "from sphere import Sphere\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from functools import partial\n",
    "from dh_grid import DHGrid\n",
    "from sphere import Sphere\n",
    "from img_sphere import ImageSphere\n",
    "from metrics import *\n",
    "from average_meter import AverageMeter\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 32.750 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 6.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "#dataset_path = '/mnt/data/datasets/nuscenes/v1.0-mini/'\n",
    "dataset_path = '/media/berlukas/T7 Touch/data/nuscenes'\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=dataset_path, verbose=True)\n",
    "all_cam_strings = ['CAM_FRONT','CAM_FRONT_RIGHT','CAM_BACK_RIGHT','CAM_BACK','CAM_BACK_LEFT','CAM_FRONT_LEFT']\n",
    "#all_cam_strings = ['CAM_FRONT_LEFT','CAM_FRONT_RIGHT', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']\n",
    "lidar_string = 'LIDAR_TOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateGrid(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([2, n_grid, n_grid])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[0, i, j] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[1, i, j] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "\n",
    "def createGrid_old(bw):\n",
    "        n_grid = 2 * bw\n",
    "        k = 0;\n",
    "        points = np.empty([n_grid * n_grid, 2])\n",
    "        for i in range(n_grid):\n",
    "            for j in range(n_grid):\n",
    "                points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "                points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "                k = k + 1;\n",
    "        return points\n",
    "\n",
    "def ConvertGridToEuclidean(grid):\n",
    "    cart_grid = np.zeros([3, grid.shape[1], grid.shape[2]])\n",
    "    cart_grid[0,:,:] = np.multiply(np.sin(grid[0, :,:]), np.cos(grid[1,:,:]))\n",
    "    cart_grid[1,:,:] = np.multiply(np.sin(grid[0, :, :]), np.sin(grid[1, :, :]))\n",
    "    cart_grid[2,:,:] = np.cos(grid[0, :, :])    \n",
    "    return cart_grid\n",
    "\n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])    \n",
    "    return cart_grid\n",
    "\n",
    "def rgb_to_greyscale(r,g,b):\n",
    "    return 0.2126*r + 0.7152*g + 0.0722*b\n",
    "\n",
    "def transform_from_pcl_to_cam(nusc, pointsensor, cam, pc):\n",
    "    # Points live in the point sensor frame. So they need to be transformed via global to the image plane.\n",
    "    # First step: transform the pointcloud to the ego vehicle frame for the timestamp of the sweep.\n",
    "    cs_record = nusc.get('calibrated_sensor', pointsensor['calibrated_sensor_token'])\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(cs_record['translation']))\n",
    "\n",
    "    # Second step: transform from ego to the global frame.\n",
    "    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(poserecord['translation']))\n",
    "\n",
    "    # Third step: transform from global into the ego vehicle frame for the timestamp of the image.\n",
    "    poserecord = nusc.get('ego_pose', cam['ego_pose_token'])\n",
    "    pc.translate(-np.array(poserecord['translation']))\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix.T)\n",
    "\n",
    "    # Fourth step: transform from ego into the camera.\n",
    "    cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "    pc.translate(-np.array(cs_record['translation']))\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix.T)\n",
    "    \n",
    "    return pc\n",
    "\n",
    "def transform_from_cam_to_pcl(nusc, pointsensor, cam, pc):\n",
    "    # Transform from the camera into the vehicle's ego frame\n",
    "    cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])    \n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(cs_record['translation']))\n",
    "    \n",
    "    # Transform from the ego frame (cam) to the global frame\n",
    "    poserecord = nusc.get('ego_pose', cam['ego_pose_token'])\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix)\n",
    "    pc.translate(np.array(poserecord['translation']))\n",
    "        \n",
    "    # Transform from the global frame to the ego frame of the LiDAR.\n",
    "    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])    \n",
    "    pc.translate(-np.array(poserecord['translation']))\n",
    "    pc.rotate(Quaternion(poserecord['rotation']).rotation_matrix.T)\n",
    "        \n",
    "    # Transform from the ego frame (LiDAR) to the LiDAR frame\n",
    "    cs_record = nusc.get('calibrated_sensor', pointsensor['calibrated_sensor_token'])    \n",
    "    pc.translate(-np.array(cs_record['translation']))\n",
    "    pc.rotate(Quaternion(cs_record['rotation']).rotation_matrix.T)\n",
    "    \n",
    "    return pc\n",
    "\n",
    "def project_pc_on_cam(pc, cam_intrinsics, depths):\n",
    "    # Take the actual picture (matrix multiplication with camera-matrix + renormalization).\n",
    "    points = view_points(pc.points[:3, :], cam_intrinsics, normalize=True)\n",
    "\n",
    "    # Remove points that are either outside or behind the camera. Leave a margin of 1 pixel for aesthetic reasons.\n",
    "    # Also make sure points are at least 1m in front of the camera to avoid seeing the lidar points on the camera\n",
    "    # casing for non-keyframes which are slightly out of sync.\n",
    "    min_dist = 0.0001\n",
    "    mask = np.ones(depths.shape[0], dtype=bool)\n",
    "    mask = np.logical_and(mask, depths < -1.0)\n",
    "    mask = np.logical_and(mask, points[0, :] > 1)\n",
    "    mask = np.logical_and(mask, points[0, :] < im.size[0] - 1)\n",
    "    mask = np.logical_and(mask, points[1, :] > 1)\n",
    "    mask = np.logical_and(mask, points[1, :] < im.size[1] - 1)\n",
    "    return points, mask\n",
    "\n",
    "def sample_mono_from_image(im, pc, mask):\n",
    "    n_mask = len(mask)\n",
    "    #print(f\"mask len is {n_mask}\")\n",
    "    for i in range(0,n_mask):    \n",
    "        visible = mask[i]\n",
    "        if not visible:\n",
    "            continue\n",
    "        cur_point = (points[0,i], points[1,i])    \n",
    "        px = im.getpixel(cur_point)    \n",
    "        intensity = rgb_to_greyscale(px[0], px[1], px[2])\n",
    "        pc.points[3,i] = intensity\n",
    "    return pc\n",
    "\n",
    "def visualizeRawPointCloud(cloud, jupyter = False):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "\n",
    "    if jupyter:\n",
    "        self.__visualizeJupyter(pcd)\n",
    "    else:\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "        \n",
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def writeRawPointCloud(cloud, filename):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    colors = mapIntensityToRGB(cloud[:, 3])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.io.write_point_cloud(filename, pcd)\n",
    "\n",
    "class SamplingPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        return 4\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'SamplingPointCloud':\n",
    "        return None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_bw(cls, bw, scale = 100) -> 'SamplingPointCloud':\n",
    "        grid = createGrid_old(bw)\n",
    "        xyz_grid = convertGridToEuclidean_old(grid) * scale\n",
    "        intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "        sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "        return cls(sampling_grid.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {len(nusc.scene)} scenes in the dataset.\")\n",
    "#for scene in nusc.scene:\n",
    "scene = nusc.scene[1]\n",
    "first_sample_token = scene['first_sample_token']\n",
    "sample = nusc.get('sample', first_sample_token)\n",
    "pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "bw = 100\n",
    "scale = 100\n",
    "pc = SamplingPointCloud.from_bw(bw, scale)\n",
    "\n",
    "for cam_str in all_cam_strings:  \n",
    "    print(f\"Sampling for cam {cam_str}\")\n",
    "    cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "    im = Image.open(osp.join(dataset_path, cam['filename']))    \n",
    "\n",
    "    # Transform pointcloud into the camera frame\n",
    "    pc = transform_from_pcl_to_cam(nusc, pointsensor, cam, pc)\n",
    "    # Grab the depths (camera frame z axis points away from the camera).\n",
    "    depths = pc.points[2, :]\n",
    "#    print(f\"depths {depths[1:20]}\")\n",
    "\n",
    "    # Project the points onto the image plane\n",
    "    cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "    intrinsics = np.array(cs_record['camera_intrinsic'])\n",
    "    points, mask = project_pc_on_cam(pc, intrinsics, depths)\n",
    "    filtered_points = points[:, mask]\n",
    "\n",
    "    # Sample the intensity values from the image\n",
    "    pc = sample_mono_from_image(im, pc, mask)    \n",
    "    \n",
    "    # Transform back into the LiDAR frame\n",
    "    pc = transform_from_cam_to_pcl(nusc, pointsensor, cam, pc)\n",
    "    #visualizeRawPointCloud(pc.points.T)\n",
    "        \n",
    "visualizeRawPointCloud(pc.points.T / 100)\n",
    "#writeRawPointCloud(pc.points.T, 'test_full.ply')\n",
    "#writeRawPointCloud(pc.points.T/100, 'test_small.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init axes.\n",
    "dot_size = 2\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 16))\n",
    "ax.imshow(im)\n",
    "ax.scatter(filtered_points[0, :], filtered_points[1, :], s=dot_size)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# Convert dataset to PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_ds = '/mnt/data/datasets/nuscenes/processed'\n",
    "# export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "# export_images = export_ds + '/SPH_IMAGES/'\n",
    "# export_clouds = export_ds + '/SPH_CLOUDS/'\n",
    "bw = 100\n",
    "scale = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_scenes = 850\n",
      "chunk 1 [0, 283]\n",
      "chunk 2 [283, 566]\n",
      "chunk 3 [566, 850]\n"
     ]
    }
   ],
   "source": [
    "n_scenes = len(nusc.scene)\n",
    "per_chunk = int(n_scenes / 3)\n",
    "\n",
    "chunk1_start = 0\n",
    "chunk1_end = per_chunk\n",
    "chunk2_start = chunk1_end\n",
    "chunk2_end = chunk2_start + per_chunk\n",
    "chunk3_start = chunk2_end\n",
    "chunk3_end = n_scenes\n",
    "\n",
    "print(f\"n_scenes = {n_scenes}\")\n",
    "print(f\"chunk 1 [{chunk1_start}, {chunk1_end}]\")\n",
    "print(f\"chunk 2 [{chunk2_start}, {chunk2_end}]\")\n",
    "print(f\"chunk 3 [{chunk3_start}, {chunk3_end}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the images to PLY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progresser_images(sample, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "    sample_sphere = ImageSphere(sample)\n",
    "    return sample_sphere.sampleUsingGrid(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenes = len(nusc.scene)\n",
    "print(f\"Processing {len(nusc.scene)} scenes in the dataset.\")\n",
    "\n",
    "all_sph_images = [None] * n_scenes\n",
    "for i in tqdm(range(0, n_scenes)):\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    sample = nusc.get('sample', first_sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    pc = SamplingPointCloud.from_bw(bw, scale)\n",
    "\n",
    "    for cam_str in all_cam_strings:  \n",
    "        #print(f\"Sampling for cam {cam_str}\")\n",
    "        cam = nusc.get('sample_data', sample['data'][cam_str])\n",
    "        im = Image.open(osp.join(dataset_path, cam['filename']))    \n",
    "\n",
    "        # Transform pointcloud into the camera frame\n",
    "        pc = transform_from_pcl_to_cam(nusc, pointsensor, cam, pc)\n",
    "        # Grab the depths (camera frame z axis points away from the camera).\n",
    "        depths = pc.points[2, :]\n",
    "\n",
    "        # Project the points onto the image plane\n",
    "        cs_record = nusc.get('calibrated_sensor', cam['calibrated_sensor_token'])\n",
    "        intrinsics = np.array(cs_record['camera_intrinsic'])\n",
    "        points, mask = project_pc_on_cam(pc, intrinsics, depths)\n",
    "        filtered_points = points[:, mask]\n",
    "\n",
    "        # Sample the intensity values from the image\n",
    "        pc = sample_mono_from_image(im, pc, mask)    \n",
    "\n",
    "        # Transform back into the LiDAR frame\n",
    "        pc = transform_from_cam_to_pcl(nusc, pointsensor, cam, pc)\n",
    "        #visualizeRawPointCloud(pc.points.T)\n",
    "        \n",
    "        #filename = f\"{export_images}images{i}.ply\"\n",
    "        #writeRawPointCloud(pc.points.T, filename)\n",
    "    all_sph_images[i] = pc.points.T / scale\n",
    "    \n",
    "print(f\"Loading complete. Computing features...\")    \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "img_features = process_map(partial(progresser_images, grid=grid), all_sph_images, max_workers=8)\n",
    "\n",
    "filename = f\"{export_ds}/images.npy\"\n",
    "np.save(filename, img_features)\n",
    "print(f\"Wrote features to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pointclouds to PLYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progresser(sample, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "    sample_sphere = Sphere(sample)\n",
    "    return sample_sphere.sampleUsingGrid(grid)\n",
    "\n",
    "def writeRawPointCloud(cloud, filename):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    colors = mapIntensityToRGB(cloud[:, 3])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.io.write_point_cloud(filename, pcd)\n",
    "    \n",
    "def get_point_cloud_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    # Load a single lidar point cloud.\n",
    "    pcl_path = osp.join(dataset_path, pointsensor['filename'])\n",
    "    pc = LidarPointCloud.from_file(pcl_path)\n",
    "    return pc.points.T, sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = chunk3_start\n",
    "end = chunk3_end\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "all_point_clouds = []\n",
    "for i in tqdm(range(start, end)):\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']    \n",
    "    pc, next_sample_token = get_point_cloud_from_token(first_sample_token)\n",
    "    all_point_clouds.append(pc)\n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "        pc, next_sample_token = get_point_cloud_from_token(next_sample_token)    \n",
    "        all_point_clouds.append(pc)        \n",
    "    \n",
    "print(f\"Loaded {len(all_point_clouds)} pointclouds. Computing features...\")    \n",
    "#visualizeRawPointCloud(all_point_clouds[0])\n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "pcl_features = process_map(partial(progresser, grid=grid), all_point_clouds, max_workers=8, chunksize=100)\n",
    "\n",
    "filename = f\"{export_ds}/clouds3.npy\"\n",
    "np.save(filename, pcl_features)\n",
    "print(f\"Wrote features to {filename}\")\n",
    "\n",
    "#for i in range(0, n_scenes):   \n",
    "#    filename = f\"{export_clouds}cloud{i}.ply\"\n",
    "#    writeRawPointCloud(pcl_features[i], filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiDAR segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_point_cloud_from_token(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    pointsensor = nusc.get('sample_data', sample['data'][lidar_string])\n",
    "    # Load a single lidar point cloud.\n",
    "    pcl_path = osp.join(dataset_path, pointsensor['filename'])\n",
    "    pc = LidarPointCloud.from_file(pcl_path)\n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    \n",
    "    # Load the semantic segmentation.\n",
    "    sample_data_token = sample['data'][lidar_string]\n",
    "    lidarseg_labels_filename = osp.join(nusc.dataroot, nusc.get('lidarseg', sample_data_token)['filename'])\n",
    "    points_label = np.fromfile(lidarseg_labels_filename, dtype=np.uint8)  # [num_points]\n",
    "\n",
    "    # Combine the two.\n",
    "    return np.column_stack((points_xyz, points_label)), sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenes from 566 to 850.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91784988de9a4d24a307ea6ac3a2cf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020f1b93b90948279782f86ac04d391f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11467.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote features to /mnt/data/datasets/nuscenes/processed/sem_clouds3.npy\n"
     ]
    }
   ],
   "source": [
    "start = chunk3_start\n",
    "end = chunk3_end\n",
    "\n",
    "print(f\"Processing scenes from {start} to {end}.\")\n",
    "\n",
    "all_sem_clouds = []\n",
    "for i in tqdm(range(start, end)):\n",
    "    scene = nusc.scene[i]\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    pc, next_sample_token = get_semantic_point_cloud_from_token(first_sample_token)\n",
    "    all_sem_clouds.append(pc)\n",
    "    \n",
    "    while next_sample_token != '':    \n",
    "        pc, next_sample_token = get_semantic_point_cloud_from_token(next_sample_token)    \n",
    "        all_sem_clouds.append(pc)   \n",
    "    \n",
    "print(f\"Loading complete. Computing features...\")    \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "sem_features = process_map(partial(progresser, grid=grid), all_sem_clouds, max_workers=8, chunksize=100)    \n",
    "\n",
    "filename = f\"{export_ds}/sem_clouds3.npy\"\n",
    "np.save(filename, sem_features)\n",
    "print(f\"Wrote features to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling pointcloud shape is (40000, 3)\n"
     ]
    }
   ],
   "source": [
    "# n_clouds = len(pcl_features)\n",
    "# n_images = len(img_features)\n",
    "# assert n_clouds > 0\n",
    "# assert n_clouds == n_images\n",
    "\n",
    "i = 15\n",
    "# cur_cloud = pcl_features[i]\n",
    "cur_sem_cloud = sem_features[i]\n",
    "# cur_image = img_features[i]\n",
    "# print(f\"current spherical cloud shape: {cur_cloud.shape} and current spherical image shape {cur_image.shape}\")\n",
    "# cur_cloud = np.reshape(cur_cloud, (2, -1)).T\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (2, -1)).T\n",
    "# cur_image = np.reshape(cur_image, (1, -1)).T\n",
    "# print(f\"current reshaped cloud shape {cur_cloud.shape} and current reshaped image shape {cur_image.shape}\")\n",
    "\n",
    "pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "points_xyz = pc.points.T[:,0:3]\n",
    "print(f\"sampling pointcloud shape is {points_xyz.shape}\")\n",
    "# points_xyzi = np.column_stack((points_xyz, cur_cloud[:,1]))\n",
    "# points_xyzp = np.column_stack((points_xyz, cur_image))\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,1]))\n",
    "\n",
    "visualizeRawPointCloud(points_xyzl)\n",
    "#visualizeRawPointCloud(points_xyzp)\n",
    "#visualizeRawPointCloud(points_xyzl)\n",
    "\n",
    "#print(f\"reshaped cloud shape is {cloud.shape}\")\n",
    "#visualizeRawPointCloud(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Check decoded signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spherical_pc(feature, trans = 0, bw = 100):\n",
    "    pc = SamplingPointCloud.from_bw(bw, 1)   \n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    points_xyz[:,0] = points_xyz[:,0] + trans\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_xyz[:, 0:3])\n",
    "    colors = mapIntensityToRGB(feature[:, 0])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd    \n",
    "\n",
    "def create_cloud_pc(cloud, trans = 0):\n",
    "    cloud[:,0] = cloud[:,0] + trans\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd\n",
    "\n",
    "def compare_estimation_sphere(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_spherical_pc(decoded, trans=0, bw=bw)\n",
    "    gt_pc = create_spherical_pc(gt, trans=2.5, bw=bw)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])    \n",
    "    \n",
    "def compare_estimation_clouds(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_cloud_pc(decoded, trans=0)\n",
    "    gt_pc = create_cloud_pc(gt, trans=100)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])\n",
    "    \n",
    "def backproject_cloud(spherical, distance, bw = 100):    \n",
    "    grid, _ = DHGrid.CreateGrid(bw)\n",
    "    n_points = grid.shape[1] * grid.shape[2]\n",
    "    cart_sphere = np.zeros([n_points, 4])\n",
    "    k = 0\n",
    "    for i in range(0, grid.shape[1]):\n",
    "        for j in range(0, grid.shape[2]):\n",
    "            dist = distance[i,j]\n",
    "            if dist <= 0:\n",
    "                continue\n",
    "            cart_sphere[k,0] = dist * np.multiply(np.cos(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,1] = dist * np.multiply(np.sin(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,2] = dist * np.cos(grid[0,i,j])\n",
    "            cart_sphere[k,3] = spherical[i,j]\n",
    "            k = k + 1\n",
    "    return cart_sphere  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the decoded/gt/input signal: (1708, 9, 200, 200)/(1708, 200, 200)/(1708, 2, 200, 200).\n"
     ]
    }
   ],
   "source": [
    "decoded_filename = f\"{export_ds}/decoded.npy\"\n",
    "decoded_gt_filename = f\"{export_ds}/decoded_gt.npy\"\n",
    "decoded_input_filename = f\"{export_ds}/decoded_input.npy\"\n",
    "\n",
    "decoded_features = np.load(decoded_filename)\n",
    "decoded_gt = np.load(decoded_gt_filename)\n",
    "decoded_input = np.load(decoded_input_filename)\n",
    "print(f\"shape of the decoded/gt/input signal: {decoded_features.shape}/{decoded_gt.shape}/{decoded_input.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-288e4591d9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcur_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred_segmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mgt_segmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_sem_cloud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpixel_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_acc_per_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_segmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_segmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n\u001b[1;32m    189\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47"
     ]
    }
   ],
   "source": [
    "n_decoded = decoded_features.shape[0]\n",
    "\n",
    "avg_pixel_acc = AverageMeter()\n",
    "avg_pixel_acc_per_class = AverageMeter()\n",
    "avg_jacc = AverageMeter()\n",
    "avg_dice = AverageMeter()\n",
    "for i in range(5, 10):    \n",
    "    cur_decoded = decoded_features[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_sem_cloud = decoded_gt[i, :, :]\n",
    "    cur_input = decoded_input[i, :, :]\n",
    "    \n",
    "    pred_segmentation = torch.from_numpy(cur_decoded).cuda().int()\n",
    "    gt_segmentation = torch.from_numpy(cur_sem_cloud).cuda().int()\n",
    "    pixel_acc, pixel_acc_per_class, jacc, dice = eval_metrics(gt_segmentation, pred_segmentation, num_classes = 9)\n",
    "    avg_pixel_acc.update(pixel_acc)\n",
    "    avg_pixel_acc_per_class.update(pixel_acc_per_class)\n",
    "    avg_jacc.update(jacc)\n",
    "    avg_dice.update(dice)\n",
    "        \n",
    "    cur_decoded = np.reshape(cur_decoded, (1, -1)).T    \n",
    "    cur_sem_cloud = np.reshape(cur_sem_cloud, (1, -1)).T    \n",
    "    \n",
    "    compare_estimation_sphere(cur_decoded, cur_sem_cloud, 100)\n",
    "\n",
    "print(f'overall pixel acc = {avg_pixel_acc.avg}')\n",
    "print(f'pixel acc per class = {avg_pixel_acc_per_class.avg}')\n",
    "print(f'mean jaccard index = {avg_jacc.avg}')\n",
    "print(f'mean dice coeff = {avg_dice.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 100\n",
    "for i in range(350, 351):    \n",
    "    cur_decoded = decoded_features[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_sem_sphere = decoded_gt[i, :, :]    \n",
    "    \n",
    "    cur_decoded = np.reshape(cur_decoded, (1, -1)).T    \n",
    "    cur_sem_sphere = np.reshape(cur_sem_sphere, (1, -1)).T    \n",
    "    \n",
    "    compare_estimation_sphere(cur_decoded, cur_sem_sphere, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Semantic Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 100\n",
    "for i in range(350, 360):    \n",
    "    cur_decoded = decoded_features[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_sem_sphere = decoded_gt[i, :, :]\n",
    "    cur_input = decoded_input[i, :, :]\n",
    "    \n",
    "    est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "    gt_cloud = backproject_cloud(cur_sem_sphere, cur_input[0,:,:], bw)\n",
    "    compare_estimation_clouds(est_cloud, gt_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32826"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(decoded_gt[0, :, :] == decoded_gt[3,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
