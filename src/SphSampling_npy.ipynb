{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampled Dataset of A2D2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from matplotlib import cm\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from sphere import Sphere\n",
    "from dh_grid import DHGrid\n",
    "from laserscan import SemLaserScan\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from os.path import join\n",
    "import glob\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 elements in the folder.\n"
     ]
    }
   ],
   "source": [
    "dataroot = '/tmp/rslidar/'\n",
    "\n",
    "cloud_ds = f'{dataroot}/clouds'\n",
    "export_ds = f'{dataroot}/processed'\n",
    "elements = os.listdir(cloud_ds)\n",
    "\n",
    "print(f'Found {len(elements)} elements in the folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84697f3ef0bb486f9aed349607d37ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 clouds.\n"
     ]
    }
   ],
   "source": [
    "def retrieve_cloud(lidar_file):    \n",
    "    plydata = PlyData.read(lidar_file)\n",
    "    vertex = plydata['vertex']\n",
    "    x = vertex['x']\n",
    "    y = vertex['y']\n",
    "    z = vertex['z']\n",
    "    i = vertex['intensity']\n",
    "    c = np.zeros_like(i)\n",
    "    return np.column_stack((x,y,z,i,c))\n",
    "\n",
    "\n",
    "all_sem_clouds = []\n",
    "for ele in tqdm(elements):\n",
    "    cloud_path = f'{cloud_ds}/{ele}'\n",
    "    # pcd = o3d.io.read_point_cloud(cloud_path)    \n",
    "    # all_sem_clouds.append(np.asarray(pcd.points))\n",
    "    \n",
    "    pcd = retrieve_cloud(cloud_path)\n",
    "    all_sem_clouds.append(pcd)\n",
    "print(f'Found {len(all_sem_clouds)} clouds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33832, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.reshape(all_sem_clouds[0], (-1, 4))\n",
    "# all_sem_clouds[0].shape\n",
    "# all_sem_clouds[0] = np.reshape(all_sem_clouds[0], (-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a41af94147f4eee9c277361c7722727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote features to /tmp/rslidar//processed/clouds.npy.\n",
      "Saved clouds to /tmp/rslidar//processed/archive.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "def progresser(sample_idx, grid, auto_position=True, write_safe=False, blocking=True, progress=False):\n",
    "    sample = all_sem_clouds[sample_idx]\n",
    "    sample_sphere = Sphere(sample)\n",
    "    features = sample_sphere.sampleUsingGrid(grid)\n",
    "    return features\n",
    "\n",
    "bw = 50\n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "print(f\"Loading complete. Computing features...\")\n",
    "# parallel\n",
    "sem_idx = np.arange(0, len(all_sem_clouds))\n",
    "sample_func = partial(progresser, grid=grid)\n",
    "sem_features = process_map(sample_func, sem_idx, max_workers=16)            \n",
    "\n",
    "filename = f\"{export_ds}/clouds.npy\"\n",
    "np.save(filename, sem_features)\n",
    "print(f\"Wrote features to {filename}.\")\n",
    "\n",
    "filename = f'archive'\n",
    "np.save(f'{export_ds}/{filename}.npy', all_sem_clouds)\n",
    "print(f'Saved clouds to {export_ds}/{filename}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize extracted pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def visualizeRawPointcloud(pcl, val):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcl[:, 0:3])\n",
    "    colors = mapIntensityToRGB(val)\n",
    "#     colors = scan.sem_color_lut[pcl[:,4].astype(np.int)]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.visualization.draw_geometries([pcd], width=640,  height=480)    \n",
    "    \n",
    "def createGrid_old(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([n_grid * n_grid, 2])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])\n",
    "    return cart_grid\n",
    "\n",
    "def create_sampling_sphere(bw):\n",
    "    grid = createGrid_old(bw)\n",
    "    xyz_grid = convertGridToEuclidean_old(grid)\n",
    "    intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "    sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "    return sampling_grid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = all_sem_clouds[0]\n",
    "visualizeRawPointcloud(pc, pc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have these classes: [ 0.  1.  2.  8.  9. 20. 27. 29. 34. 35. 39. 43. 45. 48. 50. 51. 52.]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(pc[:, 4])\n",
    "print(f'we have these classes: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_sem_cloud = sem_features[110]\n",
    "\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (3, -1)).T\n",
    "pc = create_sampling_sphere(bw)\n",
    "points_xyz = pc.T[:,0:3]\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,1]))\n",
    "\n",
    "visualizeRawPointcloud(points_xyzl, points_xyzl[:, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
