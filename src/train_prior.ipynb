{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training code for Fusion Network of S2AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from data_splitter import DataSplitter\n",
    "from external_splitter import ExternalSplitter\n",
    "from training_set import TrainingSetFusedSeg\n",
    "from training_set import TrainingSetLidarSeg\n",
    "from loss import *\n",
    "\n",
    "from model_prior import Model\n",
    "\n",
    "from sphere import Sphere\n",
    "from visualize import Visualize\n",
    "from metrics import *\n",
    "from average_meter import AverageMeter\n",
    "from torchsummary import summary\n",
    "    \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CUDA...\n",
      "Setting parameters...\n",
      "Initializing data structures...\n",
      "[Model] We have [9, 20, 25, 30, 25, 20, 17] features.\n",
      "[Model] We have [100, 30, 20, 10, 5, 10, 20, 30, 100] bandwidths.\n",
      "All instances initialized.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initializing CUDA...\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f\"Setting parameters...\")\n",
    "bandwidth = 100\n",
    "learning_rate = 1e-3\n",
    "n_epochs = 1\n",
    "batch_size = 5\n",
    "num_workers = 32\n",
    "n_classes = 17\n",
    "\n",
    "print(f\"Initializing data structures...\")\n",
    "# net = FusedModel(bandwidth=bandwidth, n_classes=n_classes).cuda()\n",
    "net = Model(bandwidth=bandwidth, n_classes=n_classes).cuda()\n",
    "\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=learning_rate,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1.0e-4,\n",
    "                            nesterov=True)\n",
    "criterion = WceLovasz()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "model_save = f'test_fusion_{timestamp}'\n",
    "\n",
    "print(f\"All instances initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clouds from /media/scratch/berlukas/nuscenes/test_training/sem_clouds_16_tiny.npy and sem clouds from /media/scratch/berlukas/nuscenes/test_training/sem_clouds1_tiny.npy\n",
      "Loaded gt.\n",
      "Loaded sem clouds.\n",
      "Loaded decoded.\n",
      "Shape of input is: sem clouds ((400, 3, 200, 200)), decoded clouds ((400, 7, 200, 200)).)\n",
      "Shape of gt is (400, 3, 200, 200).\n",
      "Shape of fused sem clouds is (400, 9, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "# export_ds = '/mnt/data/datasets/nuscenes/processed'\n",
    "export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "\n",
    "# training\n",
    "sem_clouds_filename = f\"{export_ds}/test_training/sem_clouds1_tiny.npy\"\n",
    "decoded_clouds_filename = f\"{export_ds}/test_training/sem_clouds1_decoded_tiny.npy\"\n",
    "\n",
    "gt_filename = f\"{export_ds}/test_training/sem_clouds_16_tiny.npy\"\n",
    "\n",
    "print(f\"Loading clouds from {gt_filename} and sem clouds from {sem_clouds_filename}\")\n",
    "gt_features = np.load(gt_filename)\n",
    "print('Loaded gt.')\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "print('Loaded sem clouds.')\n",
    "decoded_cloud_features = np.load(decoded_clouds_filename)\n",
    "print('Loaded decoded.')\n",
    "print(f\"Shape of input is: sem clouds ({sem_cloud_features.shape}), decoded clouds ({decoded_cloud_features.shape}).)\")\n",
    "print(f\"Shape of gt is {gt_features.shape}.\")\n",
    "\n",
    "sem_cloud_features = sem_cloud_features[:,0:2,:,:]\n",
    "sem_cloud_features = np.concatenate((sem_cloud_features, decoded_cloud_features), axis=1)\n",
    "gt_features = gt_features[:, 2, :, :]\n",
    "\n",
    "# DEBUG\n",
    "# n_process = 400\n",
    "# img_features = img_features[0:n_process, :, :, :]\n",
    "# sem_cloud_features = sem_cloud_features[0:n_process, :, :]\n",
    "# decoded_cloud_features = decoded_cloud_features[0:n_process, :, :]\n",
    "# gt_features = gt_features[0:n_process, 2, :, :]\n",
    "\n",
    "# print(f\"Shape of input is: sem clouds ({sem_cloud_features.shape}), decoded clouds ({decoded_cloud_features.shape}) and imgs ({img_features.shape})\")\n",
    "# print(f\"Shape of gt is {gt_features.shape}\")\n",
    "\n",
    "print(f\"Shape of fused sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clouds from /media/scratch/berlukas/nuscenes/val/sem_clouds_val_16_tiny.npy.\n",
      "Loading decoded from /media/scratch/berlukas/nuscenes/val/decoded_val_tiny.npy.\n",
      "Shape decoded clouds is (400, 7, 200, 200) and gt clouds is (400, 3, 200, 200).\n",
      "Shape decoded clouds is (400, 9, 200, 200) and gt clouds is (400, 200, 200).\n"
     ]
    }
   ],
   "source": [
    "# --- EXTERNAL SPLITTING ---------------------------------------------\n",
    "gt_val_filename = f\"{export_ds}/val/sem_clouds_val_16_tiny.npy\"\n",
    "decoded_filename = f\"{export_ds}/val/decoded_val_tiny.npy\"\n",
    "\n",
    "\n",
    "print(f\"Loading clouds from {gt_val_filename}.\")\n",
    "gt_val = np.load(gt_val_filename)\n",
    "print(f\"Loading decoded from {decoded_filename}.\")\n",
    "decoded_val = np.load(decoded_filename)\n",
    "print(f\"Shape decoded clouds is {decoded_val.shape} and gt clouds is {gt_val.shape}.\")\n",
    "\n",
    "\n",
    "gt_val_features = np.copy(gt_val[:, 2, :, :])\n",
    "sem_val_features = gt_val[:,0:2,:,:]\n",
    "sem_val_features = np.concatenate((sem_val_features, decoded_val), axis=1)\n",
    "\n",
    "#val_features = cloud_val[:, 0:2, :, :]\n",
    "print(f\"Shape decoded clouds is {sem_val_features.shape} and gt clouds is {gt_val_features.shape}.\")\n",
    "\n",
    "# #---\n",
    "# n_val = 400\n",
    "# n_decoded = decoded_val.shape[0]\n",
    "# decoded_val = decoded_val[n_decoded-n_val:, :, :, :]\n",
    "# n_features = sem_gt_features.shape[0]\n",
    "# sem_gt_features = sem_gt_features[n_features-n_val:, :, :]\n",
    "# img_val = img_val[n_features-n_val:,:,:,:]\n",
    "# #---\n",
    "\n",
    "train_set = TrainingSetLidarSeg(sem_cloud_features, gt_features)\n",
    "val_set = TrainingSetLidarSeg(sem_val_features, gt_val_features)\n",
    "\n",
    "split = ExternalSplitter(train_set, val_set)\n",
    "train_loader, val_loader = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "train_size = split.get_train_size()\n",
    "val_size = split.get_val_size()\n",
    "test_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NORMAL SPLITTING --------------------------------------------------------\n",
    "# train_set = TrainingSetFusedSeg(sem_cloud_features, img_features, gt_features)\n",
    "# print(f\"Total size of the training set: {len(train_set)}\")\n",
    "# split = DataSplitter(train_set, False, test_train_split=1.0, shuffle=True)\n",
    "\n",
    "# # Split the data into train, val and optionally test\n",
    "# train_loader, val_loader, test_loader = split.get_split(\n",
    "#     batch_size=batch_size, num_workers=num_workers)\n",
    "# train_size = split.get_train_size()\n",
    "# val_size = split.get_val_size()\n",
    "# test_size = split.get_test_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  400\n",
      "Validation size:  400\n",
      "Test size is 0. Configured for external tests\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "if test_size == 0:\n",
    "    print('Test size is 0. Configured for external tests')\n",
    "else:\n",
    "    print(\"Testing size: \", test_size)\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_exp(optimizer, epoch_num, lr):\n",
    "    decay_rate = 0.96\n",
    "    new_lr = lr * math.pow(decay_rate, epoch_num)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "\n",
    "    return new_lr\n",
    "\n",
    "def train_fused_lidarseg(net, criterion, optimizer, writer, epoch, n_iter, loss_, t0):\n",
    "    net.train()\n",
    "    for batch_idx, (decoded, lidarseg_gt) in enumerate(train_loader):\n",
    "        decoded, lidarseg_gt = decoded.cuda().float(), lidarseg_gt.cuda().long()\n",
    "        \n",
    "        enc_fused_dec = net(decoded)        \n",
    "        loss = criterion(enc_fused_dec, lidarseg_gt)        \n",
    "        #loss_embedd = embedded_a.norm(2) + embedded_p.norm(2) + embedded_n.norm(2)\n",
    "        #loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ += float(loss)\n",
    "\n",
    "        writer.add_scalar('Train/Loss', loss, n_iter)\n",
    "        n_iter += 1\n",
    "\n",
    "        if batch_idx % 10 == 9:\n",
    "            t1 = time.time()\n",
    "            print('[Epoch %d, Batch %4d] loss: %.8f time: %.5f' %\n",
    "                  (epoch + 1, batch_idx + 1, loss_ / 10, (t1 - t0) / 60))\n",
    "            t0 = t1\n",
    "            loss_ = 0.0\n",
    "    return n_iter\n",
    "\n",
    "def validate_fused_lidarseg(net, criterion, optimizer, writer, epoch, n_iter):\n",
    "    avg_pixel_acc = AverageMeter()\n",
    "    avg_pixel_acc_per_class = AverageMeter()\n",
    "    avg_jacc = AverageMeter()\n",
    "    avg_dice = AverageMeter()\n",
    "    net.eval()\n",
    "    with torch.no_grad():            \n",
    "        for batch_idx, (decoded, lidarseg_gt) in enumerate(val_loader):\n",
    "            decoded, lidarseg_gt = decoded.cuda().float(), lidarseg_gt.cuda().long()                \n",
    "            enc_fused_dec = net(decoded)\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(enc_fused_dec, lidarseg_gt)                                                                                        \n",
    "            writer.add_scalar('Validation/Loss', float(loss), n_iter)                        \n",
    "            \n",
    "            pred_segmentation = torch.argmax(enc_fused_dec, dim=1)\n",
    "            mask = lidarseg_gt <= 0\n",
    "            pred_segmentation[mask] = 0\n",
    "            \n",
    "            pixel_acc, pixel_acc_per_class, jacc, dice = eval_metrics(lidarseg_gt, pred_segmentation, num_classes = n_classes)\n",
    "            avg_pixel_acc.update(pixel_acc)\n",
    "            avg_pixel_acc_per_class.update(pixel_acc_per_class)\n",
    "            avg_jacc.update(jacc)\n",
    "            avg_dice.update(dice)\n",
    "\n",
    "            n_iter += 1\n",
    "            \n",
    "        epoch_p_1 = epoch+1\n",
    "        writer.add_scalar('Validation/AvgPixelAccuracy', avg_pixel_acc.avg, epoch_p_1)   \n",
    "        writer.add_scalar('Validation/AvgPixelAccuracyPerClass', avg_pixel_acc_per_class.avg, epoch_p_1)   \n",
    "        writer.add_scalar('Validation/AvgJaccardIndex', avg_jacc.avg, epoch_p_1)\n",
    "        writer.add_scalar('Validation/AvgDiceCoefficient', avg_dice.avg, epoch_p_1)  \n",
    "        \n",
    "        print('\\n')\n",
    "        print(f'[Validation for epoch {epoch_p_1}] Average Pixel Accuracy: {avg_pixel_acc.avg}')\n",
    "        print(f'[Validation for epoch {epoch_p_1}] Average Pixel Accuracy per Class: {avg_pixel_acc_per_class.avg}')\n",
    "        print(f'[Validation for epoch {epoch_p_1}] Average Jaccard Index: {avg_jacc.avg}')\n",
    "        print(f'[Validation for epoch {epoch_p_1}] Average DICE Coefficient: {avg_dice.avg}')\n",
    "        print('\\n')\n",
    "\n",
    "    return n_iter\n",
    "\n",
    "def test_fused_lidarseg(net, criterion, writer):\n",
    "    all_input_clouds = [None] * test_size\n",
    "    all_input_images = [None] * test_size\n",
    "    all_decoded_clouds = [None] * test_size\n",
    "    all_gt_clouds = [None] * test_size\n",
    "    k = 0\n",
    "    avg_pixel_acc = AverageMeter()\n",
    "    avg_pixel_acc_per_class = AverageMeter()\n",
    "    avg_jacc = AverageMeter()\n",
    "    avg_dice = AverageMeter()\n",
    "    n_iter = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (decoded, lidarseg_gt) in enumerate(test_loader):\n",
    "            decoded, lidarseg_gt = decoded.cuda().float(), image.cuda().float(), lidarseg_gt.cuda().long()                \n",
    "            enc_fused_dec = net(decoded, image)        \n",
    "            \n",
    "            pred_segmentation = torch.argmax(enc_fused_dec, dim=1)\n",
    "            pixel_acc, pixel_acc_per_class, jacc, dice = eval_metrics(lidarseg_gt, pred_segmentation, num_classes = n_classes)\n",
    "            avg_pixel_acc.update(pixel_acc)\n",
    "            avg_pixel_acc_per_class.update(pixel_acc_per_class)\n",
    "            avg_jacc.update(jacc)\n",
    "            avg_dice.update(dice)\n",
    "            \n",
    "            writer.add_scalar('Test/PixelAccuracy', pixel_acc, n_iter)   \n",
    "            writer.add_scalar('Test/PixelAccuracyPerClass', pixel_acc_per_class, n_iter)   \n",
    "            writer.add_scalar('Test/JaccardIndex', jacc, n_iter)\n",
    "            writer.add_scalar('Test/DiceCoefficient', dice, n_iter)  \n",
    "            \n",
    "            n_batch = enc_fused_dec.shape[0]\n",
    "            for i in range(0, n_batch):                                \n",
    "                all_input_clouds[k] = decoded.cpu().data.numpy()[i,:,:,:]\n",
    "                all_input_images[k] = image.cpu().data.numpy()[i,:,:,:]\n",
    "                all_decoded_clouds[k] = enc_fused_dec.cpu().data.numpy()[i,:,:,:]\n",
    "                all_gt_clouds[k] = lidarseg_gt.cpu().data.numpy()[i,:,:]\n",
    "                k = k + 1     \n",
    "            n_iter += 1\n",
    "            \n",
    "        writer.add_scalar('Test/AvgPixelAccuracy', avg_pixel_acc.avg, n_iter)   \n",
    "        writer.add_scalar('Test/AvgPixelAccuracyPerClass', avg_pixel_acc_per_class.avg, n_iter)   \n",
    "        writer.add_scalar('Test/AvgJaccardIndex', avg_jacc.avg, n_iter)\n",
    "        writer.add_scalar('Test/AvgDiceCoefficient', avg_dice.avg, n_iter)  \n",
    "        \n",
    "        print('\\n')\n",
    "        print(f'[Test] Average Pixel Accuracy: {avg_pixel_acc.avg}')\n",
    "        print(f'[Test] Average Pixel Accuracy per Class: {avg_pixel_acc_per_class.avg}')\n",
    "        print(f'[Test] Average Jaccard Index: {avg_jacc.avg}')\n",
    "        print(f'[Test] Average DICE Coefficient: {avg_dice.avg}')\n",
    "        print('\\n')\n",
    "\n",
    "    return all_input_clouds, all_input_images, all_decoded_clouds, all_gt_clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c243b3dd0b4868bf591b3b12ea3f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   10] loss: 8.96913505 time: 0.43732\n",
      "[Epoch 1, Batch   20] loss: 5.15949659 time: 0.12955\n",
      "[Epoch 1, Batch   30] loss: 4.22911448 time: 0.12952\n",
      "[Epoch 1, Batch   40] loss: 3.52716482 time: 0.12950\n",
      "[Epoch 1, Batch   50] loss: 3.14560332 time: 0.12939\n",
      "[Epoch 1, Batch   60] loss: 3.04536488 time: 0.12976\n",
      "[Epoch 1, Batch   70] loss: 2.66632445 time: 0.12989\n",
      "[Epoch 1, Batch   80] loss: 2.74410322 time: 0.12951\n",
      "\n",
      "\n",
      "[Validation for epoch 1] Average Pixel Accuracy: 0.8852795958518982\n",
      "[Validation for epoch 1] Average Pixel Accuracy per Class: 0.17275187373161316\n",
      "[Validation for epoch 1] Average Jaccard Index: 0.1326737403869629\n",
      "[Validation for epoch 1] Average DICE Coefficient: 0.1685681939125061\n",
      "\n",
      "\n",
      "\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "abort = False\n",
    "train_iter = 0\n",
    "val_iter = 0\n",
    "loss_ = 0.0\n",
    "print(f'Starting training using {n_epochs} epochs')\n",
    "for epoch in tqdm(range(n_epochs)):    \n",
    "#     lr = adjust_learning_rate_exp(optimizer, epoch_num=epoch, lr=learning_rate)\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_iter = train_fused_lidarseg(net, criterion, optimizer, writer, epoch, train_iter, loss_, t0)    \n",
    "    scheduler.step()    \n",
    "    val_iter = validate_fused_lidarseg(net, criterion, optimizer, writer, epoch, val_iter)\n",
    "    \n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    writer.add_scalar('Train/lr', lr, epoch)\n",
    "        \n",
    "print(\"Training finished!\")\n",
    "torch.save(net.state_dict(), model_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_size > 0:\n",
    "    print(\"Starting testing...\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    input_clouds, input_images, decoded_clouds, gt_clouds = test_fused_lidarseg(net, criterion, writer)\n",
    "\n",
    "    dec_input_clouds = f\"{export_ds}/decoded_fused_input_clouds.npy\"\n",
    "    dec_input_images = f\"{export_ds}/decoded_fused_input_images.npy\"\n",
    "    dec_clouds = f\"{export_ds}/decoded_fused.npy\"\n",
    "    dec_gt = f\"{export_ds}/decoded_fused_gt.npy\"\n",
    "\n",
    "    np.save(dec_input_clouds, input_clouds)\n",
    "    np.save(dec_input_images, input_images)\n",
    "    np.save(dec_clouds, decoded_clouds)\n",
    "    np.save(dec_gt, gt_clouds)\n",
    "    print(f'Wrote input clouds to {dec_input_clouds}.')\n",
    "    print(f'Wrote input images to {dec_input_images}.')\n",
    "    print(f'Wrote upsampled decoded clouds to {dec_clouds}')\n",
    "    print(f'Wrote upsampled gt clouds to {dec_gt}')\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Testing finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
