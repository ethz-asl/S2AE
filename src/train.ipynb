{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training code for S2AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from average_meter import AverageMeter\n",
    "from data_splitter import DataSplitter\n",
    "from training_set import TrainingSetLidarSeg\n",
    "from loss import L2Loss\n",
    "from model import Model\n",
    "from model_encode_decode_simple import ModelEncodeDecodeSimple\n",
    "from sphere import Sphere\n",
    "from visualize import Visualize\n",
    "    \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize some parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CUDA...\n",
      "Setting parameters...\n",
      "Initializing data structures...\n",
      "All instances initialized.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initializing CUDA...\")\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f\"Setting parameters...\")\n",
    "bandwidth = 100\n",
    "n_features = 2\n",
    "learning_rate = 4.5e-3\n",
    "n_epochs = 1\n",
    "batch_size = 1\n",
    "num_workers = 32\n",
    "descriptor_size = 256\n",
    "net_input_size = 2 * bandwidth\n",
    "\n",
    "print(f\"Initializing data structures...\")\n",
    "net = ModelEncodeDecodeSimple(bandwidth).cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = L2Loss(alpha=0.5, margin=0.2)\n",
    "writer = SummaryWriter()\n",
    "model_save = 'test_training_params.pkl'\n",
    "print(f\"All instances initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from images from /mnt/data/datasets/nuscenes/processed/images.npy, clouds from /mnt/data/datasets/nuscenes/processed/clouds.npy and sem clouds from /mnt/data/datasets/nuscenes/processed/sem_clouds.npy\n",
      "Shape of images is (10, 2, 200, 200), clouds is (10, 2, 200, 200) and sem clouds is (10, 2, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "export_ds = '/mnt/data/datasets/nuscenes/processed'\n",
    "img_filename = f\"{export_ds}/images.npy\"\n",
    "cloud_filename = f\"{export_ds}/clouds.npy\"\n",
    "sem_clouds_filename = f\"{export_ds}/sem_clouds.npy\"\n",
    "\n",
    "print(f\"Loading from images from {img_filename}, clouds from {cloud_filename} and sem clouds from {sem_clouds_filename}\")\n",
    "img_features = np.load(img_filename)\n",
    "cloud_features = np.load(cloud_filename)\n",
    "sem_cloud_features = np.load(sem_clouds_filename)\n",
    "print(f\"Shape of images is {img_features.shape}, clouds is {cloud_features.shape} and sem clouds is {sem_cloud_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the training set: 10\n",
      "Training size:  9\n",
      "Validation size:  1\n",
      "Test size is 0. Configured for external tests\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data loaders\n",
    "train_set = TrainingSetLidarSeg(bandwidth, cloud_features, sem_cloud_features)\n",
    "print(f\"Total size of the training set: {len(train_set)}\")\n",
    "split = DataSplitter(train_set, False, test_train_split=1.0, shuffle=True)\n",
    "\n",
    "# Split the data into train, val and optionally test\n",
    "train_loader, val_loader, test_loader = split.get_split(\n",
    "    batch_size=batch_size, num_workers=num_workers)\n",
    "train_size = split.get_train_size()\n",
    "val_size = split.get_val_size()\n",
    "test_size = split.get_test_size()\n",
    "print(\"Training size: \", train_size)\n",
    "print(\"Validation size: \", val_size)\n",
    "if test_size == 0:\n",
    "    print('Test size is 0. Configured for external tests')\n",
    "else:\n",
    "    print(\"Testing size: \", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_exp(optimizer, epoch_num, lr):\n",
    "    decay_rate = 0.96\n",
    "    new_lr = lr * math.pow(decay_rate, epoch_num)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "\n",
    "    return new_lr\n",
    "\n",
    "def accuracy(dista, distb):\n",
    "    margin = 0\n",
    "    pred = (dista - distb - margin).cpu().data\n",
    "    acc = ((pred < 0).sum()).float() / dista.size(0)\n",
    "    return acc\n",
    "\n",
    "def train_lidarseg(net, criterion, optimizer, writer, epoch, n_iter, loss_, t0):\n",
    "    train_dist_gt = AverageMeter()    \n",
    "    net.train()\n",
    "    for batch_idx, (cloud, lidarseg_gt) in enumerate(train_loader):\n",
    "        cloud, lidarseg_gt = cloud.cuda().float(), lidarseg_gt.cuda().float()\n",
    "        \n",
    "        enc_dec_cloud = net(cloud)\n",
    "        distance_cloud_gt, loss, loss_total = criterion(enc_dec_cloud, lidarseg_gt)\n",
    "        #loss_embedd = embedded_a.norm(2) + embedded_p.norm(2) + embedded_n.norm(2)\n",
    "        #loss = loss_triplet + 0.001 * loss_embedd\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ += loss_total.item()\n",
    "\n",
    "        train_dist_gt.update(distance_cloud_gt.cpu().data.numpy().sum())        \n",
    "        writer.add_scalar('Train/Loss', loss, n_iter)\n",
    "        writer.add_scalar('Train/Distance/GT', train_dist_gt.avg, n_iter)\n",
    "        n_iter += 1\n",
    "\n",
    "        if batch_idx % 5 == 4:\n",
    "            t1 = time.time()\n",
    "            print('[Epoch %d, Batch %4d] loss: %.8f time: %.5f lr: %.3e' %\n",
    "                  (epoch + 1, batch_idx + 1, loss_ / 5, (t1 - t0) / 60, lr))\n",
    "            t0 = t1\n",
    "            loss_ = 0.0\n",
    "    return n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2f7d6d074e44dd915f1356eb608ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[Epoch 1, Batch    5] loss: 0.75094311 time: 0.03694 lr: 4.500e-03\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "[conv] x shape is torch.Size([900, 1, 2, 2]) and y shape is torch.Size([900, 2, 10, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "encoded x shape is torch.Size([1, 10, 60, 60, 60])\n",
      "size of x: torch.Size([1, 10, 60, 60, 60]),  w torch.Size([60])\n",
      "size of x reshaped torch.Size([36000, 60])\n",
      "integrated x shape is torch.Size([1, 10, 60, 60])\n",
      "[conv] x shape is torch.Size([900, 1, 10, 2]) and y shape is torch.Size([900, 10, 2, 2])\n",
      "nspec = 35990\n",
      "b_in = 30\n",
      "ass = 35990\n",
      "decoded x shape is torch.Size([1, 2, 200, 200, 200])\n",
      "size of x: torch.Size([1, 2, 200, 200, 200]),  w torch.Size([200])\n",
      "size of x reshaped torch.Size([80000, 200])\n",
      "integrated x shape is torch.Size([1, 2, 200, 200])\n",
      "\n",
      "Training finished!\n",
      "Starting testing...\n",
      "Testing finished!\n"
     ]
    }
   ],
   "source": [
    "abort = False\n",
    "train_iter = 0\n",
    "val_iter = 0\n",
    "loss_ = 0.0\n",
    "val_accs = AverageMeter()\n",
    "print(f'Starting training using {n_epochs} epochs')\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    lr = adjust_learning_rate_exp(optimizer, epoch_num=epoch, lr=learning_rate)\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_iter = train_lidarseg(net, criterion, optimizer, writer, epoch, train_iter, loss_, t0)    \n",
    "    #val_iter = validate(net, criterion, optimizer, writer, epoch, val_iter)\n",
    "    writer.add_scalar('Train/lr', lr, epoch)\n",
    "\n",
    "print(\"Training finished!\")\n",
    "torch.save(net.state_dict(), model_save)\n",
    "\n",
    "# Test\n",
    "print(\"Starting testing...\")\n",
    "torch.cuda.empty_cache()\n",
    "#test(net, criterion, writer)\n",
    "#print(\"Testing finished!\")\n",
    "writer.close()\n",
    "print(\"Testing finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
