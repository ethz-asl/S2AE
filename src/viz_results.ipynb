{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Decoded Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "from nuscenes.utils.data_classes import PointCloud, LidarPointCloud, RadarPointCloud, Box\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from matplotlib import cm\n",
    "from sphere import Sphere\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from functools import partial\n",
    "from dh_grid import DHGrid\n",
    "from sphere import Sphere\n",
    "from img_sphere import ImageSphere\n",
    "from metrics import *\n",
    "from average_meter import AverageMeter\n",
    "import time\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m decoded_clouds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(decoded_filename)\n\u001b[1;32m      8\u001b[0m cloud_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(cloud_filename)\n\u001b[0;32m---> 10\u001b[0m decoded_gt \u001b[38;5;241m=\u001b[39m \u001b[43mcloud_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m cloud_features \u001b[38;5;241m=\u001b[39m cloud_features[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m, :, :]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the decoded signal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoded_clouds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "# export_ds = '/mnt/data/datasets/nuscenes/processed'\n",
    "export_ds = '/tmp/rslidar/decoded/'\n",
    "# export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "\n",
    "decoded_filename = f\"{export_ds}/sem_clouds_decoded.npy\"\n",
    "cloud_filename = f\"{export_ds}/sem_clouds.npy\"\n",
    "decoded_clouds = np.load(decoded_filename)\n",
    "cloud_features = np.load(cloud_filename)\n",
    "\n",
    "decoded_gt = cloud_features[:, 2, :, :]\n",
    "cloud_features = cloud_features[:, 0:2, :, :]\n",
    "\n",
    "print(f\"Shape of the decoded signal: {decoded_clouds.shape}.\")\n",
    "print(f\"Shape of the input signal GT: {decoded_gt.shape}.\")\n",
    "print(f\"Shape of the input signal: {cloud_features.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of loaded clouds is (120, 6, 100, 100) and gt is (120, 2, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "export_ds = '/tmp/rslidar/decoded/'\n",
    "# export_ds = '/media/berlukas/Data/data/nuscenes/'\n",
    "cloud_filename = f\"{export_ds}/sem_clouds_decoded.npy\"\n",
    "gt_filename = f\"{export_ds}/sem_clouds.npy\"\n",
    "decoded_clouds = np.load(cloud_filename)\n",
    "decoded_gt = np.load(gt_filename)\n",
    "\n",
    "print(f'shape of loaded clouds is {decoded_clouds.shape} and gt is {decoded_gt.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_ds = ''\n",
    "\n",
    "dec_input_clouds = f\"{export_ds}/decoded_fused_input_clouds.npy\"\n",
    "dec_input_images = f\"{export_ds}/decoded_fused_input_images.npy\"\n",
    "dec_clouds = f\"{export_ds}/decoded_fused.npy\"\n",
    "dec_gt = f\"{export_ds}/decoded_fused_gt.npy\"\n",
    "\n",
    "input_clouds = np.load(dec_input_clouds)\n",
    "input_images = np.load(dec_input_images)\n",
    "decoded_clouds = np.load(dec_clouds)\n",
    "decoded_gt = np.load(dec_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateGrid(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([2, n_grid, n_grid])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[0, i, j] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[1, i, j] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "\n",
    "def createGrid_old(bw):\n",
    "        n_grid = 2 * bw\n",
    "        k = 0;\n",
    "        points = np.empty([n_grid * n_grid, 2])\n",
    "        for i in range(n_grid):\n",
    "            for j in range(n_grid):\n",
    "                points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "                points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "                k = k + 1;\n",
    "        return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])    \n",
    "    return cart_grid\n",
    "\n",
    "def mapIntensityToRGB(i):\n",
    "    # return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "    map = np.array([[0,0,0],\n",
    "                    [1,0,0],\n",
    "                    [0,1,0],\n",
    "                    [0,0,1],\n",
    "                    [1,1,0],\n",
    "                    [0,1,1]])\n",
    "    return map[i,:]\n",
    "\n",
    "class SamplingPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        return 4\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'SamplingPointCloud':\n",
    "        return None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_bw(cls, bw, scale = 100) -> 'SamplingPointCloud':\n",
    "        grid = createGrid_old(bw)\n",
    "        xyz_grid = convertGridToEuclidean_old(grid) * scale\n",
    "        intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "        sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "        return cls(sampling_grid.T)\n",
    "\n",
    "def create_spherical_pc(feature, trans = 0, bw = 100):\n",
    "    pc = SamplingPointCloud.from_bw(bw, 1)   \n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    points_xyz[:,0] = points_xyz[:,0] + trans\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_xyz[:, 0:3])\n",
    "    colors = mapIntensityToRGB(feature[:, 0])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd    \n",
    "\n",
    "def create_cloud_pc(cloud, trans = 0):\n",
    "    cloud[:,0] = cloud[:,0] + trans\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd\n",
    "\n",
    "def compare_estimation_sphere(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_spherical_pc(decoded, trans=0, bw=bw)\n",
    "    gt_pc = create_spherical_pc(gt, trans=2.5, bw=bw)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])    \n",
    "    \n",
    "def compare_estimation_clouds(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_cloud_pc(decoded, trans=0)\n",
    "    gt_pc = create_cloud_pc(gt, trans=100)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])\n",
    "    \n",
    "def backproject_cloud(spherical, distance, bw = 100):    \n",
    "    grid, _ = DHGrid.CreateGrid(bw)\n",
    "    n_points = grid.shape[1] * grid.shape[2]\n",
    "    cart_sphere = np.zeros([n_points, 4])\n",
    "    k = 0\n",
    "    for i in range(0, grid.shape[1]):\n",
    "        for j in range(0, grid.shape[2]):\n",
    "            dist = distance[i,j]\n",
    "            if dist <= 0:\n",
    "                continue\n",
    "            cart_sphere[k,0] = dist * np.multiply(np.cos(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,1] = dist * np.multiply(np.sin(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,2] = dist * np.cos(grid[0,i,j])\n",
    "            cart_sphere[k,3] = spherical[i,j]\n",
    "            k = k + 1\n",
    "    return cart_sphere  \n",
    "\n",
    "def prepare_for_viz(cloud, colors = None):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    if cloud.shape[1] == 6:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cloud[:,3:6] / 255.0)    \n",
    "    return pcd\n",
    "\n",
    "def convert_sphere(sph, feature_idx, n_features, bw, trans = 0.0):\n",
    "    sph = np.reshape(sph, (n_features, -1)).T\n",
    "    \n",
    "    pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    points_xyz[:,0] = points_xyz[:,0] + trans\n",
    "    return np.column_stack((points_xyz, sph[:,feature_idx]))\n",
    "    \n",
    "def visualize_pointcloud(cloud, colors = None):\n",
    "    pcd = prepare_for_viz(cloud, colors)\n",
    "    o3d.visualization.draw_geometries([pcd], width=640,  height=480)\n",
    "\n",
    "def visualize_sphere(sph, feature_idx = 0, n_features = 3, bw = 100):\n",
    "    points_xyzi = convert_sphere(sph, feature_idx, n_features, bw)\n",
    "    visualize_pointcloud(points_xyzi)\n",
    "      \n",
    "def compare_estimation_sphere2(decoded, gt, bw = 100):  \n",
    "    decoded_pc = convert_sphere(decoded, 0, 1, 100)\n",
    "    gt_pc = convert_sphere(gt, 2, 3, 100, 2.5)\n",
    "    \n",
    "    decoded_pcd = prepare_for_viz(decoded_pc)\n",
    "    gt_pcd = prepare_for_viz(gt_pc)\n",
    "    o3d.visualization.draw_geometries([decoded_pcd, gt_pcd]) \n",
    "    \n",
    "def compare_estimation_sphere3(decoded, gt, feature_idx = 0, n_features = 3, bw = 100):\n",
    "    decoded_pc = convert_sphere(decoded, feature_idx, n_features, bw)\n",
    "    gt_pc = convert_sphere(gt, feature_idx, n_features, bw, 2.5)\n",
    "    \n",
    "    decoded_pcd = prepare_for_viz(decoded_pc)\n",
    "    gt_pcd = prepare_for_viz(gt_pc)\n",
    "    o3d.visualization.draw_geometries([decoded_pcd, gt_pcd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall pixel acc = 0.9346949458122253\n",
      "pixel acc per class = 0.4844251573085785\n",
      "mean jaccard index = 0.3875047564506531\n",
      "mean dice coeff = 0.466064989566803\n"
     ]
    }
   ],
   "source": [
    "n_decoded = decoded_clouds.shape[0]\n",
    "\n",
    "avg_pixel_acc = AverageMeter()\n",
    "avg_pixel_acc_per_class = AverageMeter()\n",
    "avg_jacc = AverageMeter()\n",
    "avg_dice = AverageMeter()\n",
    "for i in range(150, 160):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_sem_cloud = decoded_gt[i, :, :]\n",
    "    cur_input = cloud_features[i, :, :]\n",
    "    \n",
    "    mask = cur_sem_cloud <= 0\n",
    "    cur_decoded[mask] = 0\n",
    "    \n",
    "    pred_segmentation = torch.from_numpy(cur_decoded).cuda().int()\n",
    "    gt_segmentation = torch.from_numpy(cur_sem_cloud).cuda().int()\n",
    "    pixel_acc, pixel_acc_per_class, jacc, dice = eval_metrics(gt_segmentation, pred_segmentation, num_classes = 7)\n",
    "    avg_pixel_acc.update(pixel_acc)\n",
    "    avg_pixel_acc_per_class.update(pixel_acc_per_class)\n",
    "    avg_jacc.update(jacc)\n",
    "    avg_dice.update(dice)\n",
    "        \n",
    "    cur_decoded = np.reshape(cur_decoded, (1, -1)).T    \n",
    "    cur_sem_cloud = np.reshape(cur_sem_cloud, (1, -1)).T        \n",
    "    compare_estimation_sphere(cur_decoded, cur_sem_cloud, 100)\n",
    "\n",
    "print(f'overall pixel acc = {avg_pixel_acc.avg}')\n",
    "print(f'pixel acc per class = {avg_pixel_acc_per_class.avg}')\n",
    "print(f'mean jaccard index = {avg_jacc.avg}')\n",
    "print(f'mean dice coeff = {avg_dice.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoded pointcloud\n",
    "i = 77\n",
    "bw = 100\n",
    "\n",
    "cur_decoded = decoded_clouds[i, :, :]\n",
    "cur_gt = decoded_gt[i, :, :]\n",
    "# visualize_sphere(cur_decoded, 0, 1, 100)\n",
    "compare_estimation_sphere3(cur_decoded, cur_gt, 0, 1, 100)\n",
    "\n",
    "# mask = cur_sem_cloud <= 0\n",
    "# cur_decoded[mask] = 0\n",
    "\n",
    "# compare_estimation_sphere2(cur_decoded, cur_cloud)\n",
    "\n",
    "# compare_estimation_sphere(cur_decoded, cur_cloud)\n",
    "# visualize_sphere(cur_cloud, 2, 3, 100)\n",
    "# est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "# gt_cloud = backproject_cloud(cur_sem_sphere, cur_input[0,:,:], bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection took 148.74991577148438 ms\n"
     ]
    }
   ],
   "source": [
    "runtime = 0\n",
    "n = 400\n",
    "for i in range(0,n):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)    \n",
    "    cur_sem_cloud = decoded_gt[i, :, :]\n",
    "    mask = cur_sem_cloud <= 0\n",
    "    cur_decoded[mask] = 0\n",
    "    start_time = time.time() * 1000\n",
    "    est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "    execution_time = (time.time() * 1000 - start_time)\n",
    "    runtime = runtime + execution_time\n",
    "print(f'projection took {runtime / n} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ground truth\n",
    "i = 1\n",
    "cur_gt = decoded_gt[i, :, :]\n",
    "visualize_sphere(cur_gt, 0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Mean IoU is: 0.42056361505650336\n",
      "Class-wise IoU is: [0.58380722 0.15450794 0.         0.89509876 0.39184103 0.49812674]\n"
     ]
    }
   ],
   "source": [
    "# New IoU computation\n",
    "from iou import IoU\n",
    "\n",
    "num_classes = 7\n",
    "ignore_index = 0\n",
    "bw=100\n",
    "metric = IoU(num_classes, ignore_index=ignore_index)\n",
    "\n",
    "for i in range(0,300):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)    \n",
    "    cur_gt = decoded_gt[i, :, :]\n",
    "\n",
    "    mask = cur_gt <= 0   \n",
    "    cur_decoded[mask] = 0\n",
    "    cur_gt[mask] = 0\n",
    "\n",
    "    pred_segmentation = torch.from_numpy(np.reshape(cur_decoded, [1, 2*bw, 2*bw])).cuda().int()\n",
    "    gt_segmentation = torch.from_numpy(np.reshape(cur_gt, [1, 2*bw, 2*bw])).cuda().int()\n",
    "    metric.add(pred_segmentation, gt_segmentation)\n",
    "iou, miou = metric.value()\n",
    "\n",
    "print('========================')\n",
    "print(f'Mean IoU is: {miou}')\n",
    "print(f'Class-wise IoU is: {iou[1:]}')    \n",
    "compare_estimation_sphere(np.reshape(cur_decoded, (1, -1)).T , np.reshape(cur_gt, (1, -1)).T, 100)\n",
    "# visualize_sphere(cur_decoded, 0, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/tmp/rslidar/decoded/'\n",
    "\n",
    "clouds = sorted(os.listdir(dataroot))\n",
    "n_clouds = len(clouds)\n",
    "for i in tqdm(range(0, n_clouds)):\n",
    "    filename = f'{dataroot}/{clouds[i]}'\n",
    "    print(f'visualizing {filename}')\n",
    "    cloud = np.load(filename)\n",
    "    visualize_sphere(cloud, 0, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/tmp/rslidar/decoded/'\n",
    "\n",
    "sequences = sorted(os.listdir(dataroot))\n",
    "n_sequences = len(clouds)\n",
    "for i in tqdm(range(0, n_sequences)):\n",
    "    filename = f'{dataroot}/{sequences[i]}'\n",
    "    print(f'visualizing {filename}')    \n",
    "    clouds = np.load(filename)\n",
    "    n_clouds = clouds.shape[0]\n",
    "    for j in range(0, n_clouds):\n",
    "        cloud = clouds[j, :, :, :]\n",
    "        cloud = np.argmax(cloud, axis=0)\n",
    "        visualize_sphere(cloud, 0, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e28ada4c3e414ea76414858b42e32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing /media/berlukas/Data/data/datasets/s2ae/teaser/waymo//sem_clouds_waymo_02_val_bw50.npy\n"
     ]
    }
   ],
   "source": [
    "dataroot = '/media/berlukas/Data/data/datasets/s2ae/teaser/waymo/'\n",
    "\n",
    "sequences = sorted(os.listdir(dataroot))\n",
    "n_sequences = len(sequences)\n",
    "for i in tqdm(range(0, n_sequences)):\n",
    "    filename = f'{dataroot}/{sequences[i]}'\n",
    "    print(f'Visualizing {filename}')\n",
    "    \n",
    "    clouds = np.load(filename)\n",
    "    visualize_sphere(clouds[1], 0, 2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New New Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of loaded clouds is (278, 6, 100, 100) and gt is (278, 2, 100, 100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a26bb509ac45908a54158584a8f92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# visualize_sphere(cur_decoded, 0, 1, 50)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m est_cloud \u001b[38;5;241m=\u001b[39m backproject_cloud(cur_decoded, cur_input[\u001b[38;5;241m0\u001b[39m,:,:], bw)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mvisualize_pointcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest_cloud\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mvisualize_pointcloud\u001b[0;34m(cloud, colors)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_pointcloud\u001b[39m(cloud, colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    124\u001b[0m     pcd \u001b[38;5;241m=\u001b[39m prepare_for_viz(cloud, colors)\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpcd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    colors = cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "    map = [[0,0,0, 1], # black, unlabeled\n",
    "           [1,0,0, 1], # red, vehicle\n",
    "           [0,0,1, 1], # green, person\n",
    "           [0,0,1, 1], # blue, ground\n",
    "           [1,1,0, 1], # yellow, man-made\n",
    "           [0,1,1, 1]] # cyan, vegetation        \n",
    "    return np.array([map[int(idx)] for idx in i])        \n",
    "\n",
    "export_ds = '/tmp/rslidar/decoded/'\n",
    "# export_ds = '/media/berlukas/Data/data/nuscenes/'\n",
    "cloud_filename = f\"{export_ds}/sem_clouds_decoded.npy\"\n",
    "input_filename = f\"{export_ds}/sem_cloud_custom_val.npy\"\n",
    "decoded_clouds = np.load(cloud_filename)\n",
    "decoded_gt = np.load(input_filename)\n",
    "\n",
    "print(f'shape of loaded clouds is {decoded_clouds.shape} and gt is {decoded_gt.shape}')\n",
    "\n",
    "clouds = np.load(cloud_filename)\n",
    "inputs = np.load(input_filename)\n",
    "n_clouds = clouds.shape[0]\n",
    "n_inputs = inputs.shape[0]\n",
    "assert n_clouds == n_inputs\n",
    "\n",
    "bw = 50\n",
    "for j in tqdm(range(0, n_clouds, 2)):\n",
    "    cur_decoded = clouds[j, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_input = inputs[j, :, :, :]\n",
    "        \n",
    "    # visualize_sphere(cur_decoded, 0, 1, 50)\n",
    "    est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "    visualize_pointcloud(est_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
