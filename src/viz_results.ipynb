{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Decoded Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from pyquaternion.quaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix\n",
    "from nuscenes.utils.data_classes import PointCloud, LidarPointCloud, RadarPointCloud, Box\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from matplotlib import cm\n",
    "from sphere import Sphere\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from functools import partial\n",
    "from dh_grid import DHGrid\n",
    "from sphere import Sphere\n",
    "from img_sphere import ImageSphere\n",
    "from metrics import *\n",
    "from average_meter import AverageMeter\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_ds = '/mnt/data/datasets/nuscenes/processed'\n",
    "export_ds = '/media/berlukas/Data2/datasets/nuscenes/processed/decoded/os0'\n",
    "# export_ds = '/media/scratch/berlukas/nuscenes'\n",
    "\n",
    "decoded_filename = f\"{export_ds}/sem_clouds_decoded.npy\"\n",
    "cloud_filename = f\"{export_ds}/sem_clouds.npy\"\n",
    "decoded_clouds = np.load(decoded_filename)\n",
    "cloud_features = np.load(cloud_filename)\n",
    "\n",
    "decoded_gt = cloud_features[:, 2, :, :]\n",
    "cloud_features = cloud_features[:, 0:2, :, :]\n",
    "\n",
    "print(f\"Shape of the decoded signal: {decoded_clouds.shape}.\")\n",
    "print(f\"Shape of the input signal GT: {decoded_gt.shape}.\")\n",
    "print(f\"Shape of the input signal: {cloud_features.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of loaded clouds is (500, 200, 200) and gt is (500, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "export_ds = '/media/berlukas/Data2/datasets/nuscenes/processed/decoded/kitti'\n",
    "# export_ds = '/media/berlukas/Data/data/nuscenes/'\n",
    "cloud_filename = f\"{export_ds}/sem_clouds_decoded.npy\"\n",
    "gt_filename = f\"{export_ds}/sem_clouds_gt.npy\"\n",
    "decoded_clouds = np.load(cloud_filename)\n",
    "decoded_gt = np.load(gt_filename)\n",
    "\n",
    "print(f'shape of loaded clouds is {decoded_clouds.shape} and gt is {decoded_gt.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_ds = '/media/berlukas/Data/data/nuscenes/'\n",
    "\n",
    "dec_input_clouds = f\"{export_ds}/decoded_fused_input_clouds.npy\"\n",
    "dec_input_images = f\"{export_ds}/decoded_fused_input_images.npy\"\n",
    "dec_clouds = f\"{export_ds}/decoded_fused.npy\"\n",
    "dec_gt = f\"{export_ds}/decoded_fused_gt.npy\"\n",
    "\n",
    "input_clouds = np.load(dec_input_clouds)\n",
    "input_images = np.load(dec_input_images)\n",
    "decoded_clouds = np.load(dec_clouds)\n",
    "decoded_gt = np.load(dec_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateGrid(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([2, n_grid, n_grid])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[0, i, j] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[1, i, j] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "\n",
    "def createGrid_old(bw):\n",
    "        n_grid = 2 * bw\n",
    "        k = 0;\n",
    "        points = np.empty([n_grid * n_grid, 2])\n",
    "        for i in range(n_grid):\n",
    "            for j in range(n_grid):\n",
    "                points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "                points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "                k = k + 1;\n",
    "        return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])    \n",
    "    return cart_grid\n",
    "\n",
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "class SamplingPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        return 4\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'SamplingPointCloud':\n",
    "        return None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_bw(cls, bw, scale = 100) -> 'SamplingPointCloud':\n",
    "        grid = createGrid_old(bw)\n",
    "        xyz_grid = convertGridToEuclidean_old(grid) * scale\n",
    "        intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "        sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "        return cls(sampling_grid.T)\n",
    "\n",
    "def create_spherical_pc(feature, trans = 0, bw = 100):\n",
    "    pc = SamplingPointCloud.from_bw(bw, 1)   \n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    points_xyz[:,0] = points_xyz[:,0] + trans\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_xyz[:, 0:3])\n",
    "    colors = mapIntensityToRGB(feature[:, 0])\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd    \n",
    "\n",
    "def create_cloud_pc(cloud, trans = 0):\n",
    "    cloud[:,0] = cloud[:,0] + trans\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    return pcd\n",
    "\n",
    "def compare_estimation_sphere(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_spherical_pc(decoded, trans=0, bw=bw)\n",
    "    gt_pc = create_spherical_pc(gt, trans=2.5, bw=bw)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])    \n",
    "    \n",
    "def compare_estimation_clouds(decoded, gt, bw = 100):  \n",
    "    decoded_pc = create_cloud_pc(decoded, trans=0)\n",
    "    gt_pc = create_cloud_pc(gt, trans=100)\n",
    "    o3d.visualization.draw_geometries([decoded_pc, gt_pc])\n",
    "    \n",
    "def backproject_cloud(spherical, distance, bw = 100):    \n",
    "    grid, _ = DHGrid.CreateGrid(bw)\n",
    "    n_points = grid.shape[1] * grid.shape[2]\n",
    "    cart_sphere = np.zeros([n_points, 4])\n",
    "    k = 0\n",
    "    for i in range(0, grid.shape[1]):\n",
    "        for j in range(0, grid.shape[2]):\n",
    "            dist = distance[i,j]\n",
    "            if dist <= 0:\n",
    "                continue\n",
    "            cart_sphere[k,0] = dist * np.multiply(np.cos(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,1] = dist * np.multiply(np.sin(grid[1,i,j]), np.sin(grid[0,i,j]))\n",
    "            cart_sphere[k,2] = dist * np.cos(grid[0,i,j])\n",
    "            cart_sphere[k,3] = spherical[i,j]\n",
    "            k = k + 1\n",
    "    return cart_sphere  \n",
    "\n",
    "def prepare_for_viz(cloud):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud[:, 0:3])\n",
    "    if cloud.shape[1] == 4:\n",
    "        colors = mapIntensityToRGB(cloud[:, 3])\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    if cloud.shape[1] == 6:\n",
    "        pcd.colors = o3d.utility.Vector3dVector(cloud[:,3:6] / 255.0)\n",
    "    return pcd\n",
    "\n",
    "def convert_sphere(sph, feature_idx, n_features, bw, trans = 0.0):\n",
    "    sph = np.reshape(sph, (n_features, -1)).T\n",
    "    \n",
    "    pc = SamplingPointCloud.from_bw(bw, 1)\n",
    "    points_xyz = pc.points.T[:,0:3]\n",
    "    points_xyz[:,0] = points_xyz[:,0] + trans\n",
    "    return np.column_stack((points_xyz, sph[:,feature_idx]))\n",
    "    \n",
    "def visualize_pointcloud(cloud):\n",
    "    pcd = prepare_for_viz(cloud)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "def visualize_sphere(sph, feature_idx = 0, n_features = 3, bw = 100):\n",
    "    points_xyzi = convert_sphere(sph, feature_idx, n_features, bw)\n",
    "    visualize_pointcloud(points_xyzi)\n",
    "      \n",
    "def compare_estimation_sphere2(decoded, gt, bw = 100):  \n",
    "    decoded_pc = convert_sphere(decoded, 0, 1, 100)\n",
    "    gt_pc = convert_sphere(gt, 2, 3, 100, 2.5)\n",
    "    \n",
    "    decoded_pcd = prepare_for_viz(decoded_pc)\n",
    "    gt_pcd = prepare_for_viz(gt_pc)\n",
    "    o3d.visualization.draw_geometries([decoded_pcd, gt_pcd]) \n",
    "    \n",
    "def compare_estimation_sphere3(decoded, gt, feature_idx = 0, n_features = 3, bw = 100):\n",
    "    decoded_pc = convert_sphere(decoded, feature_idx, n_features, bw)\n",
    "    gt_pc = convert_sphere(gt, feature_idx, n_features, bw, 2.5)\n",
    "    \n",
    "    decoded_pcd = prepare_for_viz(decoded_pc)\n",
    "    gt_pcd = prepare_for_viz(gt_pc)\n",
    "    o3d.visualization.draw_geometries([decoded_pcd, gt_pcd]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall pixel acc = 0.9346949458122253\n",
      "pixel acc per class = 0.4844251573085785\n",
      "mean jaccard index = 0.3875047564506531\n",
      "mean dice coeff = 0.466064989566803\n"
     ]
    }
   ],
   "source": [
    "n_decoded = decoded_clouds.shape[0]\n",
    "\n",
    "avg_pixel_acc = AverageMeter()\n",
    "avg_pixel_acc_per_class = AverageMeter()\n",
    "avg_jacc = AverageMeter()\n",
    "avg_dice = AverageMeter()\n",
    "for i in range(150, 160):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)\n",
    "    cur_sem_cloud = decoded_gt[i, :, :]\n",
    "    cur_input = cloud_features[i, :, :]\n",
    "    \n",
    "    mask = cur_sem_cloud <= 0\n",
    "    cur_decoded[mask] = 0\n",
    "    \n",
    "    pred_segmentation = torch.from_numpy(cur_decoded).cuda().int()\n",
    "    gt_segmentation = torch.from_numpy(cur_sem_cloud).cuda().int()\n",
    "    pixel_acc, pixel_acc_per_class, jacc, dice = eval_metrics(gt_segmentation, pred_segmentation, num_classes = 7)\n",
    "    avg_pixel_acc.update(pixel_acc)\n",
    "    avg_pixel_acc_per_class.update(pixel_acc_per_class)\n",
    "    avg_jacc.update(jacc)\n",
    "    avg_dice.update(dice)\n",
    "        \n",
    "    cur_decoded = np.reshape(cur_decoded, (1, -1)).T    \n",
    "    cur_sem_cloud = np.reshape(cur_sem_cloud, (1, -1)).T        \n",
    "    compare_estimation_sphere(cur_decoded, cur_sem_cloud, 100)\n",
    "\n",
    "print(f'overall pixel acc = {avg_pixel_acc.avg}')\n",
    "print(f'pixel acc per class = {avg_pixel_acc_per_class.avg}')\n",
    "print(f'mean jaccard index = {avg_jacc.avg}')\n",
    "print(f'mean dice coeff = {avg_dice.avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decoded pointcloud\n",
    "i = 77\n",
    "bw = 100\n",
    "\n",
    "cur_decoded = decoded_clouds[i, :, :]\n",
    "cur_gt = decoded_gt[i, :, :]\n",
    "# visualize_sphere(cur_decoded, 0, 1, 100)\n",
    "compare_estimation_sphere3(cur_decoded, cur_gt, 0, 1, 100)\n",
    "\n",
    "# mask = cur_sem_cloud <= 0\n",
    "# cur_decoded[mask] = 0\n",
    "\n",
    "# compare_estimation_sphere2(cur_decoded, cur_cloud)\n",
    "\n",
    "# compare_estimation_sphere(cur_decoded, cur_cloud)\n",
    "# visualize_sphere(cur_cloud, 2, 3, 100)\n",
    "# est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "# gt_cloud = backproject_cloud(cur_sem_sphere, cur_input[0,:,:], bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection took 148.74991577148438 ms\n"
     ]
    }
   ],
   "source": [
    "runtime = 0\n",
    "n = 400\n",
    "for i in range(0,n):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)    \n",
    "    cur_sem_cloud = decoded_gt[i, :, :]\n",
    "    mask = cur_sem_cloud <= 0\n",
    "    cur_decoded[mask] = 0\n",
    "    start_time = time.time() * 1000\n",
    "    est_cloud = backproject_cloud(cur_decoded, cur_input[0,:,:], bw)\n",
    "    execution_time = (time.time() * 1000 - start_time)\n",
    "    runtime = runtime + execution_time\n",
    "print(f'projection took {runtime / n} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ground truth\n",
    "i = 1\n",
    "cur_gt = decoded_gt[i, :, :]\n",
    "visualize_sphere(cur_gt, 0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Mean IoU is: 0.42056361505650336\n",
      "Class-wise IoU is: [0.58380722 0.15450794 0.         0.89509876 0.39184103 0.49812674]\n"
     ]
    }
   ],
   "source": [
    "# New IoU computation\n",
    "from iou import IoU\n",
    "\n",
    "num_classes = 7\n",
    "ignore_index = 0\n",
    "bw=100\n",
    "metric = IoU(num_classes, ignore_index=ignore_index)\n",
    "\n",
    "for i in range(0,300):\n",
    "    cur_decoded = decoded_clouds[i, :, :, :]\n",
    "    cur_decoded = np.argmax(cur_decoded, axis=0)    \n",
    "    cur_gt = decoded_gt[i, :, :]\n",
    "\n",
    "    mask = cur_gt <= 0   \n",
    "    cur_decoded[mask] = 0\n",
    "    cur_gt[mask] = 0\n",
    "\n",
    "    pred_segmentation = torch.from_numpy(np.reshape(cur_decoded, [1, 2*bw, 2*bw])).cuda().int()\n",
    "    gt_segmentation = torch.from_numpy(np.reshape(cur_gt, [1, 2*bw, 2*bw])).cuda().int()\n",
    "    metric.add(pred_segmentation, gt_segmentation)\n",
    "iou, miou = metric.value()\n",
    "\n",
    "print('========================')\n",
    "print(f'Mean IoU is: {miou}')\n",
    "print(f'Class-wise IoU is: {iou[1:]}')    \n",
    "compare_estimation_sphere(np.reshape(cur_decoded, (1, -1)).T , np.reshape(cur_gt, (1, -1)).T, 100)\n",
    "# visualize_sphere(cur_decoded, 0, 1, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
