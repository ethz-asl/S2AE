{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sampled Dataset of KITTI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from matplotlib import cm\n",
    "from functools import partial\n",
    "import concurrent.futures\n",
    "\n",
    "from sphere import Sphere\n",
    "from dh_grid import DHGrid\n",
    "from laserscan import SemLaserScan\n",
    "from visualize import Visualize\n",
    "from utils import Utils\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dataroot to /media/berlukas/SSD_1TB/data_odometry_velodyne/dataset/sequences.\n",
      "Setting export path to /media/berlukas/Data/data/nuscenes.\n",
      "Configured 1 sequences.\n",
      "Configured config file ../config/semantic-kitti.yaml\n"
     ]
    }
   ],
   "source": [
    "def load_sequence(dataroot, sequence):\n",
    "    scan_paths = f'{dataroot}/{sequence}/velodyne'\n",
    "    scan_names = [os.path.join(dp, f) for dp, dn, fn in os.walk(\n",
    "      os.path.expanduser(scan_paths)) for f in fn]\n",
    "    scan_names.sort()\n",
    "    \n",
    "    label_paths = f'{dataroot}/{sequence}/labels'\n",
    "    label_names = [os.path.join(dp, f) for dp, dn, fn in os.walk(\n",
    "        os.path.expanduser(label_paths)) for f in fn]\n",
    "    label_names.sort()    \n",
    "    assert len(label_names) == len(scan_names)\n",
    "    print(f'Found {len(scan_names)} pointclouds and labels for sequence {sequence}.')\n",
    "    return scan_names, label_names\n",
    "\n",
    "def load_config_file(config_file):    \n",
    "    try:        \n",
    "        CFG = yaml.safe_load(open(config_file, 'r'))        \n",
    "        return CFG\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "        return None\n",
    "    \n",
    "def parse_calibration(dataroot, seq):\n",
    "    filename = dataroot + '/' + seq + '/calib.txt'\n",
    "    calib = {}\n",
    "    calib_file = open(filename)\n",
    "    for line in calib_file:\n",
    "        key, content = line.strip().split(\":\")\n",
    "        values = [float(v) for v in content.strip().split()]\n",
    "\n",
    "        pose = np.zeros((4, 4))\n",
    "        pose[0, 0:4] = values[0:4]\n",
    "        pose[1, 0:4] = values[4:8]\n",
    "        pose[2, 0:4] = values[8:12]\n",
    "        pose[3, 3] = 1.0\n",
    "\n",
    "        calib[key] = pose\n",
    "    calib_file.close()\n",
    "    return calib\n",
    "\n",
    "# dataroot = '/mnt/data/datasets/KITTI/sequences'\n",
    "# dataroot = '/media/berlukas/Data/data/datasets/KITTI/sequences'\n",
    "dataroot = '/media/berlukas/SSD_1TB/data_odometry_velodyne/dataset/sequences'\n",
    "# sequences = ['01', '02', '03']\n",
    "sequences = ['08']\n",
    "config_file = '../config/semantic-kitti.yaml'\n",
    "export_ds = '/media/berlukas/Data/data/nuscenes'\n",
    "\n",
    "print(f'Setting dataroot to {dataroot}.')\n",
    "print(f'Setting export path to {export_ds}.')\n",
    "print(f'Configured {len(sequences)} sequences.')\n",
    "print(f'Configured config file {config_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sequence 08.\n",
      "Found 4071 pointclouds and labels for sequence 08.\n",
      "This sequence has 4071 data elements.\n",
      "Processing sequence chunk from 0 to 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c083dc5b044f72aedb7729cdc43a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a71f22d0617472eb42964079dcbf635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote features to /media/berlukas/Data/data/nuscenes/clouds-08-0.npy.\n",
      "Processing sequence chunk from 1 to 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ea2fbf02184852a82d2efcab710dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71edb45609145a99253dace51591063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote features to /media/berlukas/Data/data/nuscenes/clouds-08-1.npy.\n",
      "Processing sequence chunk from 2 to 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1523bb5ad644fd89a32196989b461f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading complete. Computing features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd00998f017b4b96aa93e413372268fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-24:\n",
      "Process Process-29:\n",
      "Process Process-25:\n",
      "Process Process-22:\n",
      "Process Process-23:\n",
      "Process Process-30:\n",
      "Process Process-27:\n",
      "Process Process-26:\n",
      "Process Process-28:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/concurrent/futures/process.py\", line 169, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 93, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1d63315cf537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0msem_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sem_clouds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0msample_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogresser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0msem_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{export_ds}/clouds-{seq}-{seq_chunk_idx}.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m                  \u001b[0;34m\" Set `chunksize=1` or more.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlongest_iterable_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                  TqdmWarning, stacklevel=2)\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_executor_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         return list(tqdm_class(\n\u001b[0;32m---> 56\u001b[0;31m             ex.map(fn, *iterables, **map_args), **kwargs))\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_sem_clouds = []\n",
    "\n",
    "def progresser(sample_idx, grid, auto_position=True, write_safe=False, blocking=True, progress=False):    \n",
    "#     sample_sphere = Sphere(sample)\n",
    "    sample_sphere = all_sem_clouds[sample_idx]\n",
    "    features = sample_sphere.sampleUsingGrid(grid)\n",
    "    return features\n",
    "\n",
    "def parse_poses(dataroot, seq, calib):\n",
    "    file = dataroot + '/' + seq + '/poses.txt'\n",
    "    poses_arr = pd.read_csv(file, delimiter=' ', comment='#', header=None).to_numpy()    \n",
    "    poses = [np.array([[r[0], r[1], r[2], r[3]],\n",
    "                   [r[4], r[5], r[6], r[7]],\n",
    "                   [r[8], r[9], r[10], r[11]],\n",
    "                   [0, 0, 0, 1]]) for r in poses_arr]\n",
    "    \n",
    "    T_C_L = calib['Tr']\n",
    "    n_poses = len(poses)\n",
    "    for i in range(0, n_poses):    \n",
    "        T_G_C = poses[i]\n",
    "        poses[i] = T_G_C @ T_C_L\n",
    "    return poses\n",
    "\n",
    "def get_pointcloud_at(scan, name, label):\n",
    "    pointclouds = []            \n",
    "    scan.open_scan(name)\n",
    "    scan.open_label(label)\n",
    "    scan.colorize()\n",
    "\n",
    "    pc = np.column_stack((scan.points, scan.remissions, scan.sem_label))\n",
    "    mask = pc[:,4] > 0 # Filter based on labeled data.        \n",
    "    pointclouds.append(pc[mask])\n",
    "    return pointclouds\n",
    "\n",
    "def get_map_at(scan, names, labels, indices):\n",
    "    pointclouds = []    \n",
    "    for idx in indices:\n",
    "        scan.open_scan(names[idx])\n",
    "        scan.open_label(labels[idx])\n",
    "        scan.colorize()\n",
    "        \n",
    "        pc = np.column_stack((scan.points, scan.remissions, scan.sem_label))\n",
    "        mask = pc[:,4] > 0 # Filter based on labeled data.        \n",
    "        pointclouds.append(pc[mask])\n",
    "    return pointclouds\n",
    "\n",
    "def retrieve_poses_at(all_poses, indices):\n",
    "    poses = []\n",
    "    for idx in indices:\n",
    "        poses.append(all_poses[idx])\n",
    "    return poses\n",
    "\n",
    "def combine_pointclouds(pointclouds, poses):\n",
    "    n_data = len(poses)\n",
    "    \n",
    "    pivot = n_data // 2  \n",
    "    T_G_L_pivot = poses[pivot]\n",
    "    T_L_pivot_G = np.linalg.inv(T_G_L_pivot)\n",
    "\n",
    "    acc_points = pointclouds[pivot]\n",
    "    for i in range(0, n_data):\n",
    "        if i == pivot:\n",
    "            continue\n",
    "\n",
    "        T_G_L = poses[i]\n",
    "        T_L_pivot_L = T_L_pivot_G @ T_G_L\n",
    "\n",
    "        points = Utils.transform_pointcloud(pointclouds[i], T_L_pivot_L)\n",
    "        acc_points = np.append(acc_points, points, axis=0)                    \n",
    "    \n",
    "    return acc_points\n",
    "\n",
    "CFG = load_config_file(config_file)\n",
    "color_dict = CFG[\"color_map\"]\n",
    "nclasses = len(color_dict)\n",
    "scan = SemLaserScan(nclasses, color_dict, project=False)\n",
    "bw = 120\n",
    "assert CFG is not None\n",
    "  \n",
    "grid, _ = DHGrid.CreateGrid(bw)\n",
    "for seq in sequences:\n",
    "    print(f'Loading sequence {seq}.')    \n",
    "    scan_names, label_names = load_sequence(dataroot, seq)\n",
    "    calib = parse_calibration(dataroot, seq)\n",
    "    poses = parse_poses(dataroot, seq, calib)    \n",
    "    n_scans = len(scan_names)    \n",
    "    print(f'This sequence has {len(poses)} data elements.')\n",
    "        \n",
    "    all_sem_clouds = []\n",
    "    for i in range(0, n_scans):                \n",
    "        pointcloud = get_pointcloud_at(scan, scan_names[i], label_names[i])        \n",
    "        all_sem_clouds.append(Sphere(pointcloud[0]))\n",
    "        \n",
    "    print(f\"Loading complete. Computing features...\")\n",
    "    # parallel\n",
    "    sem_idx = np.arange(0, len(all_sem_clouds))\n",
    "    sample_func = partial(progresser, grid=grid)\n",
    "    sem_features = process_map(sample_func, sem_idx, max_workers=10, chunksize=25)            \n",
    "\n",
    "    filename = f\"{export_ds}/clouds-{seq}-{seq_chunk_idx}.npy\"\n",
    "    np.save(filename, sem_features)\n",
    "    print(f\"Wrote features to {filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIntensityToRGB(i):\n",
    "    return cm.jet(plt.Normalize(min(i), max(i))(i))\n",
    "\n",
    "def visualizeRawPointcloud(pcl, val):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pcl[:, 0:3])\n",
    "    colors = mapIntensityToRGB(val)\n",
    "#     colors = scan.sem_color_lut[pcl[:,4].astype(np.int)]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[:,0:3])\n",
    "    o3d.visualization.draw_geometries([pcd])    \n",
    "    \n",
    "def createGrid_old(bw):\n",
    "    n_grid = 2 * bw\n",
    "    k = 0;\n",
    "    points = np.empty([n_grid * n_grid, 2])\n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            points[k, 0] = (np.pi*(2*i+1))/(4*bw)\n",
    "            points[k, 1] = (2*np.pi*j)/(2*bw);\n",
    "            k = k + 1;\n",
    "    return points\n",
    "    \n",
    "def convertGridToEuclidean_old(grid):\n",
    "    cart_grid = np.zeros([ grid.shape[0], 3])\n",
    "    cart_grid[:,0] = np.multiply(np.sin(grid[:,0]), np.cos(grid[:,1]))\n",
    "    cart_grid[:,1] = np.multiply(np.sin(grid[:,0]), np.sin(grid[:,1]))\n",
    "    cart_grid[:,2] = np.cos(grid[:,0])\n",
    "    return cart_grid\n",
    "\n",
    "def create_sampling_sphere(bw):\n",
    "    grid = createGrid_old(bw)\n",
    "    xyz_grid = convertGridToEuclidean_old(grid)\n",
    "    intensities = np.zeros((xyz_grid.shape[0],1))\n",
    "    sampling_grid = np.hstack((xyz_grid, np.ones((xyz_grid.shape[0], 1), dtype=xyz_grid.dtype)))\n",
    "    return sampling_grid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = all_sem_clouds[0].point_cloud\n",
    "visualizeRawPointcloud(pc, pc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57600, 4)\n",
      "sampling pointcloud shape is (57600, 3)\n",
      "feature shape is (57600, 4)\n"
     ]
    }
   ],
   "source": [
    "filename = f\"{export_ds}/clouds1000.npy\"\n",
    "sem_features = np.load(filename)\n",
    "\n",
    "\n",
    "cur_sem_cloud = sem_features[700]\n",
    "cur_sem_cloud = np.reshape(cur_sem_cloud, (4, -1)).T\n",
    "print(f'{cur_sem_cloud.shape}')\n",
    "pc = create_sampling_sphere(bw)\n",
    "points_xyz = pc.T[:,0:3]\n",
    "print(f\"sampling pointcloud shape is {points_xyz.shape}\")\n",
    "print(f\"feature shape is {cur_sem_cloud.shape}\")\n",
    "points_xyzl = np.column_stack((points_xyz, cur_sem_cloud[:,3]))\n",
    "# points_xyzn = np.column_stack((points_xyz, cur_sem_cloud[:,2]))\n",
    "\n",
    "visualizeRawPointcloud(points_xyzl, points_xyzl[:, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
